{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:20.877005Z",
     "start_time": "2024-11-17T22:15:16.125128Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE, SymNCO, PPO, POMO, RewardConstrainedPOMO\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bd30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import rl4co\n",
    "print(rl4co.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec844555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\python311.zip\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\DLLs\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\n",
      "\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\Pythonwin\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\setuptools\\_vendor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.remove(r\"c:\\users\\hyosi\\onedrive\\ut\\2024 fall\\mie1666\\project\\code\\rl4evrptw\\rl4co\")\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58a04627ea0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:21.147698Z",
     "start_time": "2024-11-17T22:15:20.877005Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_10 = EVRPTWEnv(generator_params={'num_loc': 10, \n",
    "                                    'num_station': 3,\n",
    "                                    'vehicle_limit': 3,\n",
    "                                    'vehicle_speed': 5,\n",
    "                                    'vehicle_capacity': 1.5,\n",
    "                                    'max_time': 1,\n",
    "                                    'horizon': 1,\n",
    "                                    'fuel_consumption_rate': 0.25,\n",
    "                                    'inverse_recharge_rate': 0.25})\n",
    "td_10_TEST = env_10.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_20 = EVRPTWEnv(generator_params={'num_loc': 20, \n",
    "                                     'num_station': 3,\n",
    "                                     'vehicle_limit': 3,\n",
    "                                     'vehicle_speed': 5,\n",
    "                                     'vehicle_capacity': 1.5,\n",
    "                                     'max_time': 1,\n",
    "                                     'horizon': 1,\n",
    "                                     'fuel_consumption_rate': 0.25,\n",
    "                                     'inverse_recharge_rate': 0.25})\n",
    "td_20_TEST = env_20.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_50 = EVRPTWEnv(generator_params={'num_loc': 50, \n",
    "                                     'num_station': 6,\n",
    "                                     'vehicle_limit': 6,\n",
    "                                     'vehicle_speed': 5,\n",
    "                                     'vehicle_capacity': 1.5,\n",
    "                                     'max_time': 1,\n",
    "                                     'horizon': 1,\n",
    "                                     'fuel_consumption_rate': 0.25,\n",
    "                                     'inverse_recharge_rate': 0.25})\n",
    "td_50_TEST = env_50.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_100 = EVRPTWEnv(generator_params={'num_loc': 100,\n",
    "                                    'num_station': 12,\n",
    "                                    'vehicle_limit': 12,\n",
    "                                    'vehicle_speed': 5,\n",
    "                                    'vehicle_capacity': 1.5,\n",
    "                                    'max_time': 1,\n",
    "                                    'horizon': 1,\n",
    "                                    'fuel_consumption_rate': 0.25,\n",
    "                                    'inverse_recharge_rate': 0.25})\n",
    "td_100_TEST = env_100.reset(batch_size=[100]).to(device)\n",
    "\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "# MAX_EPOCH = 1\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 50\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b92290e4554f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:25.146517Z",
     "start_time": "2024-11-17T22:15:24.187177Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy1 = AttentionModelPolicy(env_name=env_10.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy2 = AttentionModelPolicy(env_name=env_20.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy5 = AttentionModelPolicy(env_name=env_50.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_10 = REINFORCE(env_10,\n",
    "                policy1,\n",
    "                 baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_20 = REINFORCE(env_20,\n",
    "                policy2,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_50 = REINFORCE(env_50,\n",
    "                policy5,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6114690c450fabd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:27.620347Z",
     "start_time": "2024-11-17T22:15:26.115913Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 10 | Mean Untrained Test Cost: 9.408985\n",
      "Scale: 20 | Mean Untrained Test Cost: 17.372381\n",
      "Scale: 50 | Mean Untrained Test Cost: 40.112305\n",
      "Scale: 100 | Mean Untrained Test Cost: 75.287361\n"
     ]
    }
   ],
   "source": [
    "# Greedy rollouts over untrained policy\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "policy = policy1.to(device)\n",
    "out_10 = policy(td_10_TEST.clone(), env=env_10, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_20 = policy(td_20_TEST.clone(), env=env_20, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_50 = policy(td_50_TEST.clone(), env=env_50, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_100 = policy(td_100_TEST.clone(), env=env_100, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "\n",
    "rewards_untrained_10 = out_10['reward'].cpu().numpy()\n",
    "rewards_untrained_20 = out_20['reward'].cpu().numpy()\n",
    "rewards_untrained_50 = out_50['reward'].cpu().numpy()\n",
    "rewards_untrained_100 = out_100['reward'].cpu().numpy()\n",
    "rewards = [rewards_untrained_10, rewards_untrained_20, rewards_untrained_50, rewards_untrained_100]\n",
    "# print(f\"Scale: 10 | Mean Untrained Test Cost: {-rewards_untrained_10.mean():3f}\")\n",
    "scale = [10, 20, 50, 100]\n",
    "for i in range(4):\n",
    "    print(f\"Scale: {scale[i]} | Mean Untrained Test Cost: {-rewards[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f7044d2edd277c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:16:06.321995Z",
     "start_time": "2024-11-17T22:16:06.103791Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del out_10, out_20, out_50, out_100\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c64219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(rewards, raw=False):\n",
    "    valid_rewards = []\n",
    "    for reward in rewards:\n",
    "        if -reward > 1000:\n",
    "            pass\n",
    "        else:\n",
    "            valid_rewards.append(reward)\n",
    "    return np.array(valid_rewards)\n",
    "\n",
    "def get_reward_and_check(policy, test_data, env_scale):\n",
    "    rewards_trained = []\n",
    "    rewards_trained_for_fesibility = []\n",
    "    num_valids = []\n",
    "    for td_i, env_i in zip(test_data, env_scale):\n",
    "        out = policy(td_i.clone(), \n",
    "                    env=env_i, \n",
    "                    phase=\"test\", \n",
    "                    feasibility_check=True, \n",
    "                    decode_type=\"greedy\", \n",
    "                    return_actions=True)\n",
    "        valid_out = validity_check(out['reward'].cpu().numpy())\n",
    "        rewards_trained.append(valid_out)\n",
    "        num_valids.append(len(valid_out))\n",
    "\n",
    "    return rewards_trained, num_valids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83febd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:19<00:00, 10.28it/s, v_num=357, train/reward=-4.24, train/loss=-0.152, val/reward=-4.21]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:24<00:00,  8.07it/s, v_num=357, train/reward=-4.24, train/loss=-0.152, val/reward=-4.21]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP1.fit(model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d474c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=10, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.357929\n",
      "Scale: 20 | FeasibleCounts: 95 | Mean Trained Test Cost: 6.851532\n",
      "Scale: 50 | FeasibleCounts: 100 | Mean Trained Test Cost: 13.800399\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost: 24.466507\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "policy1 = policy1.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy1, td_scale_test, env_scale)\n",
    "# print(rewards_trained)\n",
    "print(\"Trained with Environment of C=10, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "# policy_c1 = policy_c1.to(device)\n",
    "# rewards_c_trained, num_c_valid = get_reward_and_check(policy_c1, td_scale_test, env_scale)\n",
    "# print(\"\\nTrained with Environment of C=10, S=3, EV=3 (Constrained)\")\n",
    "# for i, s in enumerate(scale):\n",
    "#     print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98a7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del rewards_trained, rewards_c_trained, num_valid\n",
    "del rewards_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5720b863b4964746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T20:08:25.046679Z",
     "start_time": "2024-11-16T19:21:39.623025Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:29<00:00,  6.82it/s, v_num=358, train/reward=-6.93, train/loss=-0.668, val/reward=-6.71]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:37<00:00,  5.28it/s, v_num=358, train/reward=-6.93, train/loss=-0.668, val/reward=-6.71]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP2.fit(model_20)\n",
    "\n",
    "# trainer_C_STEP2 = RL4COTrainer(\n",
    "#     max_epochs=MAX_EPOCH,\n",
    "#     accelerator=\"gpu\",\n",
    "#     devices=1,\n",
    "#     logger=None,\n",
    "# )\n",
    "# trainer_C_STEP2.fit(model_constrained_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0778b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=20, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.389651\n",
      "Scale: 20 | FeasibleCounts: 95 | Mean Trained Test Cost: 6.696898\n",
      "Scale: 50 | FeasibleCounts: 100 | Mean Trained Test Cost: 12.970035\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost: 22.611994\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy2 = policy2.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy2, td_scale_test, env_scale)\n",
    "print(\"Trained with Environment of C=20, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "# policy_c2 = policy_c2.to(device)\n",
    "# rewards_c_trained, num_c_valid = get_reward_and_check(policy_c2, td_scale_test, env_scale)\n",
    "# print(\"\\nTrained with Environment of C=20, S=3, EV=3 (Constrained)\")\n",
    "# for i, s in enumerate(scale):\n",
    "#     print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56417938c52d941f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T00:29:59.512536Z",
     "start_time": "2024-11-17T00:29:59.151700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del rewards_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400779ce7b643d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:13:44.513107Z",
     "start_time": "2024-11-16T20:08:26.556833Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:52<00:00,  3.80it/s, v_num=359, train/reward=-12.8, train/loss=-5.50, val/reward=-12.6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:00<00:00,  3.28it/s, v_num=359, train/reward=-12.8, train/loss=-5.50, val/reward=-12.6]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP3 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP3.fit(model_50)\n",
    "\n",
    "# trainer_c_STEP3 = RL4COTrainer(\n",
    "#     max_epochs=MAX_EPOCH,\n",
    "#     accelerator=\"gpu\",\n",
    "#     devices=1,\n",
    "#     logger=None,\n",
    "# )\n",
    "# trainer_c_STEP3.fit(model_constrained_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7115537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.580757\n",
      "Scale: 20 | FeasibleCounts: 83 | Mean Trained Test Cost: 6.744152\n",
      "Scale: 50 | FeasibleCounts: 99 | Mean Trained Test Cost: 12.632970\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost: 20.994280\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy5 = policy5.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy5, td_scale_test, env_scale)\n",
    "print(\"Trained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "# policy_c5 = policy_c5.to(device)\n",
    "# rewards_c_trained, num_c_valid = get_reward_and_check(policy_c5, td_scale_test, env_scale)\n",
    "# print(\"\\nTrained with Environment of C=50, S=6, EV=6\")\n",
    "# for i, s in enumerate(scale):\n",
    "#     print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ca2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3c964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:51<00:00,  1.80it/s, v_num=361, train/reward=-21.5, train/loss=-24.0, val/reward=-20.8] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [02:27<00:00,  1.35it/s, v_num=361, train/reward=-21.5, train/loss=-24.0, val/reward=-20.8]\n"
     ]
    }
   ],
   "source": [
    "# For C=100\n",
    "\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE_100 = 128\n",
    "TRAIN_DATA_SIZE_100 = BATCH_SIZE_100 * 200\n",
    "VAL_DATA_SIZE_100 = BATCH_SIZE_100 * 50\n",
    "\n",
    "\n",
    "policy100 = AttentionModelPolicy(env_name=env_100.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_100 = REINFORCE(env_100,\n",
    "                policy100,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "trainer_STEP4 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP4.fit(model_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be22055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=100, S=12, EV=12\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.901434\n",
      "Scale: 20 | FeasibleCounts: 57 | Mean Trained Test Cost: 7.132657\n",
      "Scale: 50 | FeasibleCounts: 94 | Mean Trained Test Cost: 12.950029\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost: 20.851795\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy100 = policy100.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy100, td_scale_test, env_scale)\n",
    "print(\"Trained with Environment of C=100, S=12, EV=12\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dc637",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12d96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
