{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:20.877005Z",
     "start_time": "2024-11-17T22:15:16.125128Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE, SymNCO, PPO, POMO, RewardConstrainedPOMO\n",
    "from rl4co.utils.trainer import RL4COTrainer\n",
    "from rl4co.utils.callbacks.reward_check import RewardLoggingCallback, get_reward_and_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bd30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import rl4co\n",
    "print(rl4co.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec844555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\python311.zip\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\DLLs\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\n",
      "\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\Pythonwin\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\setuptools\\_vendor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.remove(r\"c:\\users\\hyosi\\onedrive\\ut\\2024 fall\\mie1666\\project\\code\\rl4evrptw\\rl4co\")\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58a04627ea0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:21.147698Z",
     "start_time": "2024-11-17T22:15:20.877005Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    import random\n",
    "    import os \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # NVIDIA's CUDA Basic Linear Algebra Subroutines library\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "vehicle_capacity = 1.25\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': vehicle_capacity,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': vehicle_capacity,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b92290e4554f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:25.146517Z",
     "start_time": "2024-11-17T22:15:24.187177Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 50\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "# MAX_EPOCH = 2\n",
    "# BATCH_SIZE = 10\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 1\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 1\n",
    "\n",
    "# POMO\n",
    "policy1 = AttentionModelPolicy(env_name=soft_envs[0].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy2 = AttentionModelPolicy(env_name=soft_envs[1].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy5 = AttentionModelPolicy(env_name=soft_envs[2].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_10 = POMO(soft_envs[0],\n",
    "                policy1,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_20 = POMO(soft_envs[1],\n",
    "                policy2,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_50 = POMO(soft_envs[2],\n",
    "                policy5,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "\n",
    "# RCPOMO\n",
    "policy_c1 = AttentionModelPolicy(env_name=soft_envs[0].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_c2 = AttentionModelPolicy(env_name=soft_envs[1].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_c5 = AttentionModelPolicy(env_name=soft_envs[2].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_c10 = RewardConstrainedPOMO(soft_envs[0],\n",
    "                policy_c1,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_c20 = RewardConstrainedPOMO(soft_envs[1],\n",
    "                policy_c2,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_c50 = RewardConstrainedPOMO(soft_envs[2],\n",
    "                policy_c5,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "# RINFORCE\n",
    "policy_r1 = AttentionModelPolicy(env_name=soft_envs[0].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_r2 = AttentionModelPolicy(env_name=soft_envs[1].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_r5 = AttentionModelPolicy(env_name=soft_envs[2].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_r10 = REINFORCE(soft_envs[0],\n",
    "                policy_r1,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_r20 = REINFORCE(soft_envs[1],\n",
    "                policy_r2,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_r50 = REINFORCE(soft_envs[2],\n",
    "                policy_r5,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83febd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:22<00:00,  8.72it/s, v_num=540, train/reward=-3.41, train/loss=-0.17, val/reward=-3.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:19<00:00, 10.14it/s, v_num=540, train/reward=-3.33, train/loss=-0.12, val/reward=-3.30] Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:19<00:00, 10.27it/s, v_num=540, train/reward=-3.30, train/loss=-0.10, val/reward=-3.29]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:20<00:00,  9.87it/s, v_num=540, train/reward=-3.30, train/loss=-0.10, val/reward=-3.29]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\utils\\callbacks\\reward_check.py:56: RuntimeWarning: Mean of empty slice.\n",
      "  epoch_data[f\"C{s}_mean_reward\"] = -rewards_trained[i].mean()\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 200/200 [00:19<00:00, 10.36it/s, v_num=540, train/reward=-3.31, train/loss=-0.0815, val/reward=-3.29]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:19<00:00, 10.38it/s, v_num=540, train/reward=-3.31, train/loss=-0.0955, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:19<00:00, 10.38it/s, v_num=540, train/reward=-3.31, train/loss=-0.0768, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:19<00:00, 10.35it/s, v_num=540, train/reward=-3.28, train/loss=-0.0702, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:19<00:00, 10.36it/s, v_num=540, train/reward=-3.30, train/loss=-0.0661, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:19<00:00, 10.35it/s, v_num=540, train/reward=-3.30, train/loss=-0.0707, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:19<00:00, 10.39it/s, v_num=540, train/reward=-3.28, train/loss=-0.0772, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:19<00:00, 10.50it/s, v_num=540, train/reward=-3.27, train/loss=-0.0621, val/reward=-3.28]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:18<00:00, 10.59it/s, v_num=540, train/reward=-3.28, train/loss=-0.0632, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:19<00:00, 10.10it/s, v_num=540, train/reward=-3.27, train/loss=-0.0629, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:19<00:00, 10.47it/s, v_num=540, train/reward=-3.25, train/loss=-0.0531, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:19<00:00, 10.45it/s, v_num=540, train/reward=-3.27, train/loss=-0.0506, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:19<00:00, 10.51it/s, v_num=540, train/reward=-3.28, train/loss=-0.056, val/reward=-3.27] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:19<00:00, 10.42it/s, v_num=540, train/reward=-3.29, train/loss=-0.0644, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:19<00:00, 10.35it/s, v_num=540, train/reward=-3.27, train/loss=-0.0552, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:19<00:00, 10.38it/s, v_num=540, train/reward=-3.26, train/loss=-0.0471, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:19<00:00, 10.40it/s, v_num=540, train/reward=-3.28, train/loss=-0.0541, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:19<00:00, 10.47it/s, v_num=540, train/reward=-3.28, train/loss=-0.0542, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:18<00:00, 10.58it/s, v_num=540, train/reward=-3.23, train/loss=-0.0537, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:19<00:00, 10.49it/s, v_num=540, train/reward=-3.29, train/loss=-0.0534, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:18<00:00, 10.61it/s, v_num=540, train/reward=-3.28, train/loss=-0.0531, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:19<00:00, 10.51it/s, v_num=540, train/reward=-3.25, train/loss=-0.0482, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:18<00:00, 10.62it/s, v_num=540, train/reward=-3.25, train/loss=-0.0451, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:18<00:00, 10.72it/s, v_num=540, train/reward=-3.28, train/loss=-0.0465, val/reward=-3.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:18<00:00, 10.53it/s, v_num=540, train/reward=-3.22, train/loss=-0.0432, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:18<00:00, 10.73it/s, v_num=540, train/reward=-3.27, train/loss=-0.0502, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:18<00:00, 10.85it/s, v_num=540, train/reward=-3.28, train/loss=-0.0442, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:18<00:00, 10.67it/s, v_num=540, train/reward=-3.26, train/loss=-0.0402, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:18<00:00, 10.69it/s, v_num=540, train/reward=-3.26, train/loss=-0.0428, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:18<00:00, 10.69it/s, v_num=540, train/reward=-3.27, train/loss=-0.0402, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:18<00:00, 10.75it/s, v_num=540, train/reward=-3.26, train/loss=-0.0444, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:19<00:00, 10.06it/s, v_num=540, train/reward=-3.28, train/loss=-0.0463, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:18<00:00, 10.72it/s, v_num=540, train/reward=-3.26, train/loss=-0.0494, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:18<00:00, 10.87it/s, v_num=540, train/reward=-3.27, train/loss=-0.0374, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:18<00:00, 10.74it/s, v_num=540, train/reward=-3.27, train/loss=-0.0503, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:18<00:00, 10.69it/s, v_num=540, train/reward=-3.27, train/loss=-0.0452, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:18<00:00, 10.83it/s, v_num=540, train/reward=-3.27, train/loss=-0.0465, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:18<00:00, 10.76it/s, v_num=540, train/reward=-3.25, train/loss=-0.0398, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:18<00:00, 10.62it/s, v_num=540, train/reward=-3.27, train/loss=-0.0426, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:18<00:00, 10.67it/s, v_num=540, train/reward=-3.27, train/loss=-0.0437, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:18<00:00, 10.75it/s, v_num=540, train/reward=-3.25, train/loss=-0.0381, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:18<00:00, 10.69it/s, v_num=540, train/reward=-3.29, train/loss=-0.0408, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:18<00:00, 10.78it/s, v_num=540, train/reward=-3.27, train/loss=-0.0403, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:18<00:00, 10.70it/s, v_num=540, train/reward=-3.25, train/loss=-0.0329, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:18<00:00, 10.64it/s, v_num=540, train/reward=-3.25, train/loss=-0.0326, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:18<00:00, 10.66it/s, v_num=540, train/reward=-3.25, train/loss=-0.0427, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:18<00:00, 10.80it/s, v_num=540, train/reward=-3.25, train/loss=-0.0362, val/reward=-3.26]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:19<00:00, 10.37it/s, v_num=540, train/reward=-3.25, train/loss=-0.0362, val/reward=-3.26]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:19<00:00, 10.31it/s, v_num=540, train/reward=-3.25, train/loss=-0.0362, val/reward=-3.26]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:24<00:00,  8.25it/s, v_num=541, train/reward=-3.83, train/loss=-0.369, val/reward=-3.66]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:23<00:00,  8.47it/s, v_num=541, train/reward=-3.92, train/loss=-0.312, val/reward=-3.83]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:23<00:00,  8.59it/s, v_num=541, train/reward=-4.30, train/loss=-1.37, val/reward=-3.77] Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:25<00:00,  8.00it/s, v_num=541, train/reward=-4.12, train/loss=-1.31, val/reward=-3.77] Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:24<00:00,  8.24it/s, v_num=541, train/reward=-3.70, train/loss=-0.223, val/reward=-3.68]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:22<00:00,  8.73it/s, v_num=541, train/reward=-3.95, train/loss=-0.667, val/reward=-3.63]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:21<00:00,  9.47it/s, v_num=541, train/reward=-3.71, train/loss=-0.211, val/reward=-3.67] Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:22<00:00,  8.94it/s, v_num=541, train/reward=-3.67, train/loss=-0.198, val/reward=-3.66]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:23<00:00,  8.63it/s, v_num=541, train/reward=-3.65, train/loss=-0.176, val/reward=-3.64]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:21<00:00,  9.24it/s, v_num=541, train/reward=-3.63, train/loss=-0.161, val/reward=-3.60]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:22<00:00,  8.75it/s, v_num=541, train/reward=-3.60, train/loss=-0.16, val/reward=-3.60] Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:22<00:00,  8.75it/s, v_num=541, train/reward=-3.68, train/loss=-0.162, val/reward=-3.62]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:23<00:00,  8.64it/s, v_num=541, train/reward=-3.66, train/loss=-0.162, val/reward=-3.62] Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:21<00:00,  9.26it/s, v_num=541, train/reward=-3.63, train/loss=-0.135, val/reward=-3.59]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:20<00:00,  9.60it/s, v_num=541, train/reward=-3.60, train/loss=-0.149, val/reward=-3.60]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:22<00:00,  8.79it/s, v_num=541, train/reward=-3.63, train/loss=-0.138, val/reward=-3.59]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:20<00:00,  9.73it/s, v_num=541, train/reward=-3.60, train/loss=-0.126, val/reward=-3.59]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:20<00:00,  9.63it/s, v_num=541, train/reward=-3.55, train/loss=-0.122, val/reward=-3.55]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:20<00:00,  9.76it/s, v_num=541, train/reward=-3.58, train/loss=-0.11, val/reward=-3.56] Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:20<00:00,  9.74it/s, v_num=541, train/reward=-3.74, train/loss=-0.16, val/reward=-3.59]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:20<00:00,  9.80it/s, v_num=541, train/reward=-3.56, train/loss=-0.11, val/reward=-3.54]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:20<00:00,  9.79it/s, v_num=541, train/reward=-3.58, train/loss=-0.124, val/reward=-3.58] Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:20<00:00,  9.77it/s, v_num=541, train/reward=-3.58, train/loss=-0.103, val/reward=-3.58] Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:20<00:00,  9.90it/s, v_num=541, train/reward=-3.59, train/loss=-0.12, val/reward=-3.58]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:20<00:00,  9.88it/s, v_num=541, train/reward=-3.56, train/loss=-0.111, val/reward=-3.53]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:20<00:00,  9.80it/s, v_num=541, train/reward=-3.74, train/loss=-0.13, val/reward=-3.55]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:20<00:00,  9.86it/s, v_num=541, train/reward=-3.56, train/loss=-0.102, val/reward=-3.56] Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:20<00:00,  9.87it/s, v_num=541, train/reward=-3.58, train/loss=-0.12, val/reward=-3.53]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:20<00:00,  9.87it/s, v_num=541, train/reward=-3.58, train/loss=-0.116, val/reward=-3.55] Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:20<00:00,  9.73it/s, v_num=541, train/reward=-3.58, train/loss=-0.105, val/reward=-3.55] Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:20<00:00,  9.76it/s, v_num=541, train/reward=-3.57, train/loss=-0.0964, val/reward=-3.53]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:20<00:00,  9.90it/s, v_num=541, train/reward=-3.56, train/loss=-0.103, val/reward=-3.53] Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:20<00:00,  9.80it/s, v_num=541, train/reward=-3.57, train/loss=-0.0945, val/reward=-3.52]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:20<00:00,  9.80it/s, v_num=541, train/reward=-3.52, train/loss=-0.10, val/reward=-3.53]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:20<00:00,  9.78it/s, v_num=541, train/reward=-3.57, train/loss=-0.0988, val/reward=-3.52]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:20<00:00,  9.87it/s, v_num=541, train/reward=-3.55, train/loss=-0.106, val/reward=-3.52] Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:20<00:00,  9.81it/s, v_num=541, train/reward=-3.52, train/loss=-0.0997, val/reward=-3.52]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:20<00:00,  9.82it/s, v_num=541, train/reward=-3.52, train/loss=-0.0961, val/reward=-3.52]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:20<00:00,  9.89it/s, v_num=541, train/reward=-3.51, train/loss=-0.081, val/reward=-3.49] Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:20<00:00,  9.65it/s, v_num=541, train/reward=-3.53, train/loss=-0.0887, val/reward=-3.52]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:20<00:00,  9.85it/s, v_num=541, train/reward=-3.54, train/loss=-0.0968, val/reward=-3.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:20<00:00,  9.79it/s, v_num=541, train/reward=-3.51, train/loss=-0.0821, val/reward=-3.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:20<00:00,  9.92it/s, v_num=541, train/reward=-3.53, train/loss=-0.0838, val/reward=-3.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:20<00:00,  9.88it/s, v_num=541, train/reward=-3.50, train/loss=-0.0951, val/reward=-3.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:20<00:00,  9.73it/s, v_num=541, train/reward=-3.51, train/loss=-0.0746, val/reward=-3.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:20<00:00,  9.80it/s, v_num=541, train/reward=-3.81, train/loss=-1.46, val/reward=-3.50]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:20<00:00,  9.91it/s, v_num=541, train/reward=-3.50, train/loss=-0.0944, val/reward=-3.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:20<00:00,  9.79it/s, v_num=541, train/reward=-3.52, train/loss=-0.0837, val/reward=-3.49]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:20<00:00,  9.84it/s, v_num=541, train/reward=-3.49, train/loss=-0.0856, val/reward=-3.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:20<00:00,  9.83it/s, v_num=541, train/reward=-3.55, train/loss=-0.0907, val/reward=-3.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:21<00:00,  9.43it/s, v_num=541, train/reward=-3.55, train/loss=-0.0907, val/reward=-3.48]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:21<00:00,  9.38it/s, v_num=541, train/reward=-3.55, train/loss=-0.0907, val/reward=-3.48]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:18<00:00, 10.93it/s, v_num=542, train/reward=-3.26, train/loss=-0.144, val/reward=-3.15]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:15<00:00, 13.32it/s, v_num=542, train/reward=-3.11, train/loss=-0.00957, val/reward=-3.07]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:15<00:00, 12.97it/s, v_num=542, train/reward=-3.05, train/loss=-0.116, val/reward=-3.06]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:15<00:00, 13.07it/s, v_num=542, train/reward=-3.01, train/loss=-0.0328, val/reward=-3.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:15<00:00, 13.10it/s, v_num=542, train/reward=-3.01, train/loss=-0.0396, val/reward=-3.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:14<00:00, 14.21it/s, v_num=542, train/reward=-3.07, train/loss=-0.0815, val/reward=-3.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:13<00:00, 14.33it/s, v_num=542, train/reward=-3.04, train/loss=-0.0696, val/reward=-3.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:13<00:00, 14.31it/s, v_num=542, train/reward=-3.03, train/loss=-0.0181, val/reward=-3.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:14<00:00, 14.15it/s, v_num=542, train/reward=-3.04, train/loss=-0.0191, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:14<00:00, 13.59it/s, v_num=542, train/reward=-3.02, train/loss=-0.0156, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:13<00:00, 14.32it/s, v_num=542, train/reward=-3.02, train/loss=-0.0203, val/reward=-3.02]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:14<00:00, 14.27it/s, v_num=542, train/reward=-3.04, train/loss=-0.0212, val/reward=-3.02]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:13<00:00, 14.50it/s, v_num=542, train/reward=-3.02, train/loss=-0.0203, val/reward=-3.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:14<00:00, 14.23it/s, v_num=542, train/reward=-3.04, train/loss=-0.0281, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:13<00:00, 14.35it/s, v_num=542, train/reward=-3.03, train/loss=-0.0363, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:13<00:00, 14.36it/s, v_num=542, train/reward=-3.02, train/loss=-0.0136, val/reward=-3.02]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:13<00:00, 14.62it/s, v_num=542, train/reward=-3.02, train/loss=-0.00833, val/reward=-3.02]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:13<00:00, 14.49it/s, v_num=542, train/reward=-3.04, train/loss=-0.0129, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:13<00:00, 14.60it/s, v_num=542, train/reward=-3.02, train/loss=-0.0297, val/reward=-3.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:13<00:00, 14.29it/s, v_num=542, train/reward=-3.02, train/loss=-0.0206, val/reward=-3.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:14<00:00, 14.25it/s, v_num=542, train/reward=-3.02, train/loss=-0.0644, val/reward=-3.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:13<00:00, 14.49it/s, v_num=542, train/reward=-3.02, train/loss=2.000, val/reward=-3.01]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:14<00:00, 13.98it/s, v_num=542, train/reward=-3.06, train/loss=-0.0257, val/reward=-3.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:14<00:00, 14.06it/s, v_num=542, train/reward=-3.01, train/loss=-0.0207, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:13<00:00, 14.32it/s, v_num=542, train/reward=-3.03, train/loss=-0.0229, val/reward=-3.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:13<00:00, 14.29it/s, v_num=542, train/reward=-3.03, train/loss=-0.00588, val/reward=-3.01]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:13<00:00, 14.38it/s, v_num=542, train/reward=-3.00, train/loss=-0.00757, val/reward=-3.01]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:13<00:00, 14.29it/s, v_num=542, train/reward=-3.07, train/loss=-0.0268, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:14<00:00, 14.15it/s, v_num=542, train/reward=-3.03, train/loss=-0.00808, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:14<00:00, 14.16it/s, v_num=542, train/reward=-3.01, train/loss=-0.0043, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:13<00:00, 14.31it/s, v_num=542, train/reward=-3.01, train/loss=-0.0155, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:14<00:00, 13.89it/s, v_num=542, train/reward=-3.00, train/loss=-0.00818, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:14<00:00, 14.24it/s, v_num=542, train/reward=-3.03, train/loss=-0.00314, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:14<00:00, 14.21it/s, v_num=542, train/reward=-3.02, train/loss=-0.00309, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:13<00:00, 14.39it/s, v_num=542, train/reward=-3.00, train/loss=-0.00495, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:13<00:00, 14.42it/s, v_num=542, train/reward=-3.02, train/loss=-0.0143, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:13<00:00, 14.56it/s, v_num=542, train/reward=-3.02, train/loss=-0.0145, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:13<00:00, 14.58it/s, v_num=542, train/reward=-3.02, train/loss=-0.0053, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:13<00:00, 14.52it/s, v_num=542, train/reward=-3.01, train/loss=-0.0177, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:14<00:00, 13.73it/s, v_num=542, train/reward=-3.06, train/loss=-0.00647, val/reward=-3.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:14<00:00, 14.13it/s, v_num=542, train/reward=-3.03, train/loss=-0.00535, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:13<00:00, 14.36it/s, v_num=542, train/reward=-2.99, train/loss=-0.00557, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:13<00:00, 14.70it/s, v_num=542, train/reward=-3.03, train/loss=-0.00272, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:13<00:00, 14.77it/s, v_num=542, train/reward=-3.00, train/loss=-0.00423, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:13<00:00, 14.56it/s, v_num=542, train/reward=-3.01, train/loss=-0.0101, val/reward=-3.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:13<00:00, 14.42it/s, v_num=542, train/reward=-3.00, train/loss=-0.0312, val/reward=-3.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:13<00:00, 14.65it/s, v_num=542, train/reward=-3.03, train/loss=-0.0104, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:13<00:00, 14.49it/s, v_num=542, train/reward=-3.03, train/loss=295.0, val/reward=-3.00]    Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:13<00:00, 14.66it/s, v_num=542, train/reward=-3.02, train/loss=-0.00473, val/reward=-3.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:13<00:00, 14.59it/s, v_num=542, train/reward=-3.00, train/loss=-0.0387, val/reward=-3.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:14<00:00, 13.99it/s, v_num=542, train/reward=-3.00, train/loss=-0.0387, val/reward=-3.01]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:16<00:00, 12.35it/s, v_num=542, train/reward=-3.00, train/loss=-0.0387, val/reward=-3.01]\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "# POMO\n",
    "trainer_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy1.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_POMO_C10\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_STEP1.fit(model_10)\n",
    "\n",
    "# RCPOMO\n",
    "trainer_C_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_c1.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_RCPOMO_C10\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_C_STEP1.fit(model_c10)\n",
    "\n",
    "# REINFORCE\n",
    "trainer_R_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_r1.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_REINFORCE_C10\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_R_STEP1.fit(model_r10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d474c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POMO: Trained with Environment of C=10, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 81 | Mean Trained Test Cost: 5.261562\n",
      "Scale: 20 | FeasibleCounts: 19 | Mean Trained Test Cost: 7.248013\n",
      "Scale: 50 | FeasibleCounts: 12 | Mean Trained Test Cost: 14.381671\n",
      "Scale: 100 | FeasibleCounts: 42 | Mean Trained Test Cost: 27.189011\n",
      "\n",
      "RCPOMO: Trained with Environment of C=10, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 88 | Mean Trained Test Cost: 6.049044\n",
      "Scale: 20 | FeasibleCounts: 33 | Mean Trained Test Cost: 7.983972\n",
      "Scale: 50 | FeasibleCounts: 36 | Mean Trained Test Cost: 14.360809\n",
      "Scale: 100 | FeasibleCounts: 59 | Mean Trained Test Cost: 27.460426\n",
      "\n",
      "REINFORCE: Trained with Environment of C=10, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 89 | Mean Trained Test Cost: 4.886317\n",
      "Scale: 20 | FeasibleCounts: 32 | Mean Trained Test Cost: 6.861988\n",
      "Scale: 50 | FeasibleCounts: 23 | Mean Trained Test Cost: 13.610734\n",
      "Scale: 100 | FeasibleCounts: 59 | Mean Trained Test Cost: 24.440115\n"
     ]
    }
   ],
   "source": [
    "policy1 = policy1.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy1, td_tests, hard_envs)\n",
    "# print(rewards_trained)\n",
    "print(\"POMO: Trained with Environment of C=10, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "policy_c1 = policy_c1.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c1, td_tests, hard_envs)\n",
    "print(\"\\nRCPOMO: Trained with Environment of C=10, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost: {-rewards_c_trained[i].mean():3f}\")\n",
    "    \n",
    "policy_r1 = policy_r1.to(device)\n",
    "rewards_r_trained, num_r_valid = get_reward_and_check(policy_r1, td_tests, hard_envs)\n",
    "print(\"\\nREINFORCE: Trained with Environment of C=10, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98a7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer_STEP1, trainer_C_STEP1, trainer_R_STEP1\n",
    "del rewards_trained, rewards_c_trained, rewards_r_trained, num_valid, num_c_valid, num_r_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a224fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:37<00:00,  5.34it/s, v_num=543, train/reward=-4.70, train/loss=-0.54, val/reward=-4.56]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:33<00:00,  6.04it/s, v_num=543, train/reward=-4.54, train/loss=-0.312, val/reward=-4.46]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:32<00:00,  6.09it/s, v_num=543, train/reward=-4.47, train/loss=-0.267, val/reward=-4.43]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:32<00:00,  6.15it/s, v_num=543, train/reward=-4.45, train/loss=-0.251, val/reward=-4.42]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:32<00:00,  6.08it/s, v_num=543, train/reward=-4.46, train/loss=-0.257, val/reward=-4.41]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:32<00:00,  6.16it/s, v_num=543, train/reward=-4.41, train/loss=-0.204, val/reward=-4.40]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:32<00:00,  6.13it/s, v_num=543, train/reward=-4.43, train/loss=-0.188, val/reward=-4.39]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:32<00:00,  6.17it/s, v_num=543, train/reward=-4.42, train/loss=-0.189, val/reward=-4.39]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:32<00:00,  6.22it/s, v_num=543, train/reward=-4.40, train/loss=-0.214, val/reward=-4.39]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:31<00:00,  6.27it/s, v_num=543, train/reward=-4.41, train/loss=-0.166, val/reward=-4.38]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:32<00:00,  6.25it/s, v_num=543, train/reward=-4.40, train/loss=-0.163, val/reward=-4.38]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:31<00:00,  6.25it/s, v_num=543, train/reward=-4.37, train/loss=-0.173, val/reward=-4.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.40, train/loss=-0.158, val/reward=-4.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:32<00:00,  6.14it/s, v_num=543, train/reward=-4.40, train/loss=-0.172, val/reward=-4.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.38, train/loss=-0.16, val/reward=-4.37] Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:32<00:00,  6.16it/s, v_num=543, train/reward=-4.37, train/loss=-0.153, val/reward=-4.36]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:32<00:00,  6.12it/s, v_num=543, train/reward=-4.39, train/loss=-0.147, val/reward=-4.36]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:32<00:00,  6.13it/s, v_num=543, train/reward=-4.39, train/loss=-0.144, val/reward=-4.36]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:32<00:00,  6.16it/s, v_num=543, train/reward=-4.37, train/loss=-0.14, val/reward=-4.36] Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.38, train/loss=-0.134, val/reward=-4.36]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.39, train/loss=-0.136, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:32<00:00,  6.11it/s, v_num=543, train/reward=-4.37, train/loss=-0.125, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:32<00:00,  6.19it/s, v_num=543, train/reward=-4.37, train/loss=-0.132, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.37, train/loss=-0.141, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:32<00:00,  6.19it/s, v_num=543, train/reward=-4.36, train/loss=-0.126, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:32<00:00,  6.20it/s, v_num=543, train/reward=-4.36, train/loss=-0.137, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:32<00:00,  6.15it/s, v_num=543, train/reward=-4.35, train/loss=-0.134, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.37, train/loss=-0.123, val/reward=-4.35]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:32<00:00,  6.24it/s, v_num=543, train/reward=-4.35, train/loss=-0.124, val/reward=-4.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:32<00:00,  6.22it/s, v_num=543, train/reward=-4.36, train/loss=-0.124, val/reward=-4.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:32<00:00,  6.20it/s, v_num=543, train/reward=-4.32, train/loss=-0.108, val/reward=-4.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:32<00:00,  6.19it/s, v_num=543, train/reward=-4.36, train/loss=-0.12, val/reward=-4.34] Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:32<00:00,  6.19it/s, v_num=543, train/reward=-4.34, train/loss=-0.132, val/reward=-4.34] Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.35, train/loss=-0.121, val/reward=-4.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:32<00:00,  6.23it/s, v_num=543, train/reward=-4.36, train/loss=-0.118, val/reward=-4.33]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:32<00:00,  6.20it/s, v_num=543, train/reward=-4.35, train/loss=-0.135, val/reward=-4.34] Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.33, train/loss=-0.124, val/reward=-4.33]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:31<00:00,  6.28it/s, v_num=543, train/reward=-4.36, train/loss=-0.122, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:31<00:00,  6.30it/s, v_num=543, train/reward=-4.35, train/loss=-0.122, val/reward=-4.33]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:31<00:00,  6.36it/s, v_num=543, train/reward=-4.37, train/loss=-0.119, val/reward=-4.34]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.36, train/loss=-0.122, val/reward=-4.33]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:32<00:00,  6.19it/s, v_num=543, train/reward=-4.35, train/loss=-0.116, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:32<00:00,  6.22it/s, v_num=543, train/reward=-4.34, train/loss=-0.103, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:32<00:00,  6.21it/s, v_num=543, train/reward=-4.35, train/loss=-0.111, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.35, train/loss=-0.123, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:32<00:00,  6.17it/s, v_num=543, train/reward=-4.33, train/loss=-0.105, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.33, train/loss=-0.107, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:32<00:00,  6.18it/s, v_num=543, train/reward=-4.35, train/loss=-0.10, val/reward=-4.33]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:32<00:00,  6.25it/s, v_num=543, train/reward=-4.34, train/loss=-0.116, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:32<00:00,  6.22it/s, v_num=543, train/reward=-4.36, train/loss=-0.121, val/reward=-4.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:32<00:00,  6.08it/s, v_num=543, train/reward=-4.36, train/loss=-0.121, val/reward=-4.33]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:33<00:00,  6.06it/s, v_num=543, train/reward=-4.36, train/loss=-0.121, val/reward=-4.33]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:37<00:00,  5.35it/s, v_num=544, train/reward=-6.77, train/loss=-3.09, val/reward=-6.25]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:36<00:00,  5.44it/s, v_num=544, train/reward=-6.73, train/loss=-2.51, val/reward=-6.11]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:34<00:00,  5.78it/s, v_num=544, train/reward=-6.32, train/loss=-1.53, val/reward=-5.92] Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:34<00:00,  5.86it/s, v_num=544, train/reward=-6.07, train/loss=-0.952, val/reward=-5.85]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:34<00:00,  5.86it/s, v_num=544, train/reward=-5.93, train/loss=-0.824, val/reward=-5.66]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:34<00:00,  5.82it/s, v_num=544, train/reward=-5.90, train/loss=-0.867, val/reward=-5.70]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:35<00:00,  5.68it/s, v_num=544, train/reward=-6.02, train/loss=-1.25, val/reward=-5.79] Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:35<00:00,  5.69it/s, v_num=544, train/reward=-5.83, train/loss=-0.687, val/reward=-5.68]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:34<00:00,  5.78it/s, v_num=544, train/reward=-5.84, train/loss=-0.742, val/reward=-5.66]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:35<00:00,  5.71it/s, v_num=544, train/reward=-5.95, train/loss=-1.51, val/reward=-5.63] Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:35<00:00,  5.69it/s, v_num=544, train/reward=-5.72, train/loss=-0.639, val/reward=-5.60]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:35<00:00,  5.71it/s, v_num=544, train/reward=-5.80, train/loss=-0.567, val/reward=-5.67]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:35<00:00,  5.65it/s, v_num=544, train/reward=-5.65, train/loss=-0.544, val/reward=-5.57]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:34<00:00,  5.72it/s, v_num=544, train/reward=-5.65, train/loss=-0.618, val/reward=-5.54]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:35<00:00,  5.69it/s, v_num=544, train/reward=-5.76, train/loss=-0.609, val/reward=-5.59]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:34<00:00,  5.75it/s, v_num=544, train/reward=-5.82, train/loss=-1.21, val/reward=-5.50] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.68, train/loss=-0.716, val/reward=-5.45]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s, v_num=544, train/reward=-5.78, train/loss=-1.12, val/reward=-5.59] Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s, v_num=544, train/reward=-5.65, train/loss=-0.44, val/reward=-5.54] Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s, v_num=544, train/reward=-5.68, train/loss=-0.465, val/reward=-5.56]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.63, train/loss=-0.695, val/reward=-5.47]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:34<00:00,  5.72it/s, v_num=544, train/reward=-5.67, train/loss=-0.686, val/reward=-5.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.62, train/loss=-0.649, val/reward=-5.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.64, train/loss=-0.498, val/reward=-5.51]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s, v_num=544, train/reward=-5.77, train/loss=-1.16, val/reward=-5.55] Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:34<00:00,  5.75it/s, v_num=544, train/reward=-5.56, train/loss=-0.515, val/reward=-5.49]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:34<00:00,  5.75it/s, v_num=544, train/reward=-5.60, train/loss=-0.828, val/reward=-5.45]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.54, train/loss=-0.418, val/reward=-5.42]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:35<00:00,  5.71it/s, v_num=544, train/reward=-5.51, train/loss=-0.388, val/reward=-5.42]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s, v_num=544, train/reward=-5.47, train/loss=-0.492, val/reward=-5.40]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:34<00:00,  5.74it/s, v_num=544, train/reward=-5.54, train/loss=-0.369, val/reward=-5.46]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:34<00:00,  5.84it/s, v_num=544, train/reward=-5.51, train/loss=-0.369, val/reward=-5.44]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:34<00:00,  5.82it/s, v_num=544, train/reward=-5.59, train/loss=-0.65, val/reward=-5.42] Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:34<00:00,  5.81it/s, v_num=544, train/reward=-5.52, train/loss=-0.434, val/reward=-5.42]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:34<00:00,  5.79it/s, v_num=544, train/reward=-5.81, train/loss=-1.16, val/reward=-5.44] Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:34<00:00,  5.85it/s, v_num=544, train/reward=-5.58, train/loss=-0.541, val/reward=-5.43]Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:34<00:00,  5.81it/s, v_num=544, train/reward=-5.58, train/loss=-1.86, val/reward=-5.38] Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:34<00:00,  5.79it/s, v_num=544, train/reward=-5.41, train/loss=-0.335, val/reward=-5.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:34<00:00,  5.76it/s, v_num=544, train/reward=-5.53, train/loss=-1.20, val/reward=-5.36] Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:34<00:00,  5.75it/s, v_num=544, train/reward=-5.41, train/loss=-1.05, val/reward=-5.31] Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:34<00:00,  5.72it/s, v_num=544, train/reward=-5.41, train/loss=-0.302, val/reward=-5.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:34<00:00,  5.75it/s, v_num=544, train/reward=-5.40, train/loss=-0.30, val/reward=-5.32] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:34<00:00,  5.78it/s, v_num=544, train/reward=-5.35, train/loss=-0.343, val/reward=-5.29]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:34<00:00,  5.72it/s, v_num=544, train/reward=-5.46, train/loss=-0.311, val/reward=-5.33] Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:34<00:00,  5.76it/s, v_num=544, train/reward=-5.37, train/loss=-0.332, val/reward=-5.31] Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:34<00:00,  5.80it/s, v_num=544, train/reward=-5.31, train/loss=-0.32, val/reward=-5.27] Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:34<00:00,  5.77it/s, v_num=544, train/reward=-5.44, train/loss=-0.53, val/reward=-5.28] Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:34<00:00,  5.81it/s, v_num=544, train/reward=-5.33, train/loss=-0.28, val/reward=-5.26] Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:34<00:00,  5.81it/s, v_num=544, train/reward=-5.32, train/loss=-0.271, val/reward=-5.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:34<00:00,  5.79it/s, v_num=544, train/reward=-5.35, train/loss=-0.312, val/reward=-5.28] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:35<00:00,  5.66it/s, v_num=544, train/reward=-5.35, train/loss=-0.312, val/reward=-5.28]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:35<00:00,  5.64it/s, v_num=544, train/reward=-5.35, train/loss=-0.312, val/reward=-5.28]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [00:26<00:00,  7.42it/s, v_num=545, train/reward=-4.99, train/loss=19.50, val/reward=-4.64]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:24<00:00,  8.26it/s, v_num=545, train/reward=-4.54, train/loss=-0.127, val/reward=-4.35]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:23<00:00,  8.38it/s, v_num=545, train/reward=-4.36, train/loss=1.300, val/reward=-4.24]     Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:23<00:00,  8.58it/s, v_num=545, train/reward=-4.28, train/loss=-0.559, val/reward=-4.16]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:23<00:00,  8.59it/s, v_num=545, train/reward=-4.20, train/loss=-0.336, val/reward=-4.14]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:23<00:00,  8.59it/s, v_num=545, train/reward=-4.16, train/loss=-0.368, val/reward=-4.12] Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:22<00:00,  8.70it/s, v_num=545, train/reward=-4.15, train/loss=-0.244, val/reward=-4.10] Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:23<00:00,  8.55it/s, v_num=545, train/reward=-4.17, train/loss=-0.251, val/reward=-4.12] Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:23<00:00,  8.60it/s, v_num=545, train/reward=-4.17, train/loss=-0.202, val/reward=-4.10]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [00:23<00:00,  8.50it/s, v_num=545, train/reward=-4.16, train/loss=-0.14, val/reward=-4.11]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:23<00:00,  8.59it/s, v_num=545, train/reward=-4.12, train/loss=-0.0497, val/reward=-4.10] Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:23<00:00,  8.57it/s, v_num=545, train/reward=-4.14, train/loss=-0.0233, val/reward=-4.09]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:22<00:00,  8.70it/s, v_num=545, train/reward=-4.12, train/loss=0.0247, val/reward=-4.07]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:22<00:00,  8.76it/s, v_num=545, train/reward=-4.11, train/loss=0.0764, val/reward=-4.07]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:23<00:00,  8.65it/s, v_num=545, train/reward=-4.12, train/loss=-0.057, val/reward=-4.08]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:23<00:00,  8.68it/s, v_num=545, train/reward=-4.09, train/loss=-0.0578, val/reward=-4.07] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:23<00:00,  8.62it/s, v_num=545, train/reward=-4.11, train/loss=0.0172, val/reward=-4.06]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:23<00:00,  8.66it/s, v_num=545, train/reward=-4.06, train/loss=0.123, val/reward=-4.05]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:22<00:00,  8.77it/s, v_num=545, train/reward=-4.09, train/loss=-0.0239, val/reward=-4.05] Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:23<00:00,  8.57it/s, v_num=545, train/reward=-4.05, train/loss=0.0528, val/reward=-4.05]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:22<00:00,  8.73it/s, v_num=545, train/reward=-4.09, train/loss=0.0922, val/reward=-4.04]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:22<00:00,  8.76it/s, v_num=545, train/reward=-4.04, train/loss=0.124, val/reward=-4.03]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:22<00:00,  8.72it/s, v_num=545, train/reward=-4.06, train/loss=0.152, val/reward=-4.03]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:23<00:00,  8.68it/s, v_num=545, train/reward=-4.07, train/loss=0.179, val/reward=-4.03]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:23<00:00,  8.65it/s, v_num=545, train/reward=-4.10, train/loss=0.0887, val/reward=-4.04] Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:23<00:00,  8.67it/s, v_num=545, train/reward=-4.10, train/loss=-0.000285, val/reward=-4.06]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:22<00:00,  8.74it/s, v_num=545, train/reward=-4.07, train/loss=0.0645, val/reward=-4.04]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:24<00:00,  8.04it/s, v_num=545, train/reward=-4.05, train/loss=0.0821, val/reward=-4.03]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:23<00:00,  8.65it/s, v_num=545, train/reward=-4.05, train/loss=0.131, val/reward=-4.03]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:22<00:00,  8.74it/s, v_num=545, train/reward=-4.04, train/loss=0.153, val/reward=-4.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:23<00:00,  8.68it/s, v_num=545, train/reward=-375., train/loss=-1.02e+3, val/reward=-4.02]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:22<00:00,  8.72it/s, v_num=545, train/reward=-4.05, train/loss=0.103, val/reward=-4.02]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:23<00:00,  8.63it/s, v_num=545, train/reward=-4.05, train/loss=0.159, val/reward=-4.03]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:22<00:00,  8.70it/s, v_num=545, train/reward=-4.02, train/loss=0.0796, val/reward=-4.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:23<00:00,  8.57it/s, v_num=545, train/reward=-4.06, train/loss=0.129, val/reward=-4.03]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:22<00:00,  8.74it/s, v_num=545, train/reward=-4.05, train/loss=0.145, val/reward=-4.02]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:23<00:00,  8.62it/s, v_num=545, train/reward=-4.05, train/loss=0.0826, val/reward=-4.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:22<00:00,  8.74it/s, v_num=545, train/reward=-4.03, train/loss=0.136, val/reward=-4.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:22<00:00,  8.74it/s, v_num=545, train/reward=-4.06, train/loss=0.0992, val/reward=-4.02]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:22<00:00,  8.75it/s, v_num=545, train/reward=-4.02, train/loss=0.111, val/reward=-4.01]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:22<00:00,  8.72it/s, v_num=545, train/reward=-4.02, train/loss=0.154, val/reward=-4.01]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:23<00:00,  8.66it/s, v_num=545, train/reward=-4.04, train/loss=0.129, val/reward=-4.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:23<00:00,  8.69it/s, v_num=545, train/reward=-4.04, train/loss=0.104, val/reward=-4.02]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:22<00:00,  8.76it/s, v_num=545, train/reward=-4.04, train/loss=0.159, val/reward=-4.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:23<00:00,  8.69it/s, v_num=545, train/reward=-4.03, train/loss=0.166, val/reward=-4.01]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:23<00:00,  8.69it/s, v_num=545, train/reward=-4.03, train/loss=0.105, val/reward=-4.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:22<00:00,  8.82it/s, v_num=545, train/reward=-4.02, train/loss=0.098, val/reward=-4.02]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:22<00:00,  8.84it/s, v_num=545, train/reward=-4.05, train/loss=0.0928, val/reward=-4.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:22<00:00,  8.80it/s, v_num=545, train/reward=-4.02, train/loss=0.125, val/reward=-4.01]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:23<00:00,  8.68it/s, v_num=545, train/reward=-4.05, train/loss=0.0999, val/reward=-4.01]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:23<00:00,  8.44it/s, v_num=545, train/reward=-4.05, train/loss=0.0999, val/reward=-4.01]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:27<00:00,  7.41it/s, v_num=545, train/reward=-4.05, train/loss=0.0999, val/reward=-4.01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# POMO\n",
    "trainer_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy2.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_POMO_C20\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_STEP2.fit(model_20)\n",
    "\n",
    "# RCPOMO\n",
    "trainer_C_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_c2.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_RCPOMO_C20\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_C_STEP2.fit(model_c20)\n",
    "\n",
    "# REINFORCE\n",
    "trainer_R_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_r2.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_REINFORCE_C20\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_R_STEP2.fit(model_r20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04145ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POMO: Trained with Environment of C=20, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 67 | Mean Trained Test Cost: 5.930059\n",
      "Scale: 20 | FeasibleCounts: 10 | Mean Trained Test Cost: 8.054955\n",
      "Scale: 50 | FeasibleCounts: 1 | Mean Trained Test Cost: 14.269993\n",
      "Scale: 100 | FeasibleCounts: 4 | Mean Trained Test Cost: 31.162970\n",
      "\n",
      "RCPOMO: Trained with Environment of C=20, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 52 | Mean Trained Test Cost: 7.404771\n",
      "Scale: 20 | FeasibleCounts: 11 | Mean Trained Test Cost: 8.119093\n",
      "Scale: 50 | FeasibleCounts: 5 | Mean Trained Test Cost: 14.787048\n",
      "Scale: 100 | FeasibleCounts: 13 | Mean Trained Test Cost: 27.750549\n",
      "\n",
      "REINFORCE: Trained with Environment of C=20, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 90 | Mean Trained Test Cost: 4.901956\n",
      "Scale: 20 | FeasibleCounts: 29 | Mean Trained Test Cost: 6.734668\n",
      "Scale: 50 | FeasibleCounts: 25 | Mean Trained Test Cost: 13.449342\n",
      "Scale: 100 | FeasibleCounts: 71 | Mean Trained Test Cost: 24.103729\n"
     ]
    }
   ],
   "source": [
    "policy2 = policy2.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy2, td_tests, hard_envs)\n",
    "# print(rewards_trained)\n",
    "print(\"POMO: Trained with Environment of C=20, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "policy_c2 = policy_c2.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c2, td_tests, hard_envs)\n",
    "print(\"\\nRCPOMO: Trained with Environment of C=20, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost: {-rewards_c_trained[i].mean():3f}\")\n",
    "    \n",
    "policy_r2 = policy_r2.to(device)\n",
    "rewards_r_trained, num_r_valid = get_reward_and_check(policy_r2, td_tests, hard_envs)\n",
    "print(\"\\nREINFORCE: Trained with Environment of C=20, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b939bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer_STEP2, trainer_C_STEP2, trainer_R_STEP2\n",
    "del rewards_trained, rewards_c_trained, rewards_r_trained, num_valid, num_c_valid, num_r_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d3043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [01:48<00:00,  1.84it/s, v_num=546, train/reward=-7.85, train/loss=-1.48, val/reward=-7.37]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [01:41<00:00,  1.98it/s, v_num=546, train/reward=-7.36, train/loss=-1.56, val/reward=-6.99]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=546, train/reward=-7.11, train/loss=-0.977, val/reward=-6.84]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [01:44<00:00,  1.91it/s, v_num=546, train/reward=-7.04, train/loss=-0.99, val/reward=-6.80] Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=546, train/reward=-7.07, train/loss=-1.31, val/reward=-6.80] Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [01:41<00:00,  1.97it/s, v_num=546, train/reward=-7.25, train/loss=-1.68, val/reward=-6.86]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=546, train/reward=-7.53, train/loss=-2.39, val/reward=-7.24]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [01:40<00:00,  1.98it/s, v_num=546, train/reward=-7.44, train/loss=-1.78, val/reward=-7.00]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [01:45<00:00,  1.90it/s, v_num=546, train/reward=-7.51, train/loss=-1.29, val/reward=-7.06]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [01:47<00:00,  1.86it/s, v_num=546, train/reward=-7.43, train/loss=-1.31, val/reward=-7.01]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [01:42<00:00,  1.95it/s, v_num=546, train/reward=-7.43, train/loss=-1.59, val/reward=-7.03] Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=546, train/reward=-7.36, train/loss=-1.16, val/reward=-7.02] Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [01:40<00:00,  1.98it/s, v_num=546, train/reward=-7.29, train/loss=-1.18, val/reward=-6.98] Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [01:42<00:00,  1.96it/s, v_num=546, train/reward=-7.29, train/loss=-1.16, val/reward=-6.97] Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [01:43<00:00,  1.94it/s, v_num=546, train/reward=-7.48, train/loss=-1.48, val/reward=-7.05] Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [01:40<00:00,  1.99it/s, v_num=546, train/reward=-7.47, train/loss=-1.48, val/reward=-7.06] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [01:40<00:00,  1.98it/s, v_num=546, train/reward=-7.43, train/loss=-1.29, val/reward=-7.10] Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [01:43<00:00,  1.94it/s, v_num=546, train/reward=-7.81, train/loss=-2.96, val/reward=-7.30] Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=546, train/reward=-7.78, train/loss=-1.67, val/reward=-7.42] Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [01:42<00:00,  1.95it/s, v_num=546, train/reward=-7.61, train/loss=-1.04, val/reward=-7.19] Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [01:39<00:00,  2.01it/s, v_num=546, train/reward=-7.36, train/loss=-0.825, val/reward=-7.08]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [01:39<00:00,  2.01it/s, v_num=546, train/reward=-7.85, train/loss=-1.17, val/reward=-7.39] Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [01:41<00:00,  1.97it/s, v_num=546, train/reward=-7.86, train/loss=-0.986, val/reward=-7.42]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [01:42<00:00,  1.96it/s, v_num=546, train/reward=-8.01, train/loss=-1.98, val/reward=-7.61] Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [01:44<00:00,  1.91it/s, v_num=546, train/reward=-7.91, train/loss=-2.28, val/reward=-7.42] Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [01:40<00:00,  1.99it/s, v_num=546, train/reward=-7.67, train/loss=-1.03, val/reward=-7.41] Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [01:47<00:00,  1.86it/s, v_num=546, train/reward=-48.7, train/loss=-405., val/reward=-7.12] Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [01:50<00:00,  1.81it/s, v_num=546, train/reward=-8.18, train/loss=-1.13, val/reward=-7.70] Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [01:41<00:00,  1.97it/s, v_num=546, train/reward=-7.84, train/loss=-1.09, val/reward=-7.46] Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [01:40<00:00,  1.99it/s, v_num=546, train/reward=-7.64, train/loss=-0.979, val/reward=-7.40]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [01:44<00:00,  1.92it/s, v_num=546, train/reward=-8.28, train/loss=-0.977, val/reward=-7.84]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=546, train/reward=-24.7, train/loss=-112., val/reward=-9.74]    Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [02:11<00:00,  1.52it/s, v_num=546, train/reward=-21.5, train/loss=-64.7, val/reward=-10.4]    Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=546, train/reward=-21.9, train/loss=-94.4, val/reward=-7.81] Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=546, train/reward=-14.5, train/loss=-51.8, val/reward=-7.48]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [01:41<00:00,  1.98it/s, v_num=546, train/reward=-8.10, train/loss=-1.06, val/reward=-7.67]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [01:41<00:00,  1.97it/s, v_num=546, train/reward=-7.71, train/loss=-0.89, val/reward=-7.41] Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [01:38<00:00,  2.02it/s, v_num=546, train/reward=-7.69, train/loss=-0.818, val/reward=-7.39]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [01:38<00:00,  2.03it/s, v_num=546, train/reward=-7.57, train/loss=-0.764, val/reward=-7.36]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=546, train/reward=-8.99, train/loss=-1.80, val/reward=-8.25]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [01:41<00:00,  1.98it/s, v_num=546, train/reward=-7.81, train/loss=-0.562, val/reward=-7.44]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [01:39<00:00,  2.01it/s, v_num=546, train/reward=-7.76, train/loss=-0.626, val/reward=-7.47]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [01:41<00:00,  1.97it/s, v_num=546, train/reward=-7.76, train/loss=-1.08, val/reward=-7.52] Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [01:49<00:00,  1.83it/s, v_num=546, train/reward=-7.81, train/loss=-0.654, val/reward=-7.56]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [01:37<00:00,  2.04it/s, v_num=546, train/reward=-7.83, train/loss=-0.81, val/reward=-7.60] Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=546, train/reward=-11.8, train/loss=-2.65, val/reward=-10.9]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [01:42<00:00,  1.95it/s, v_num=546, train/reward=-8.61, train/loss=-1.14, val/reward=-9.15]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [01:40<00:00,  2.00it/s, v_num=546, train/reward=-9.01, train/loss=-1.05, val/reward=-8.54]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [01:38<00:00,  2.03it/s, v_num=546, train/reward=-8.63, train/loss=-1.18, val/reward=-8.01] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [01:39<00:00,  2.02it/s, v_num=546, train/reward=-8.21, train/loss=-0.973, val/reward=-7.90] Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [01:39<00:00,  2.01it/s, v_num=546, train/reward=-8.21, train/loss=-0.973, val/reward=-7.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:39<00:00,  2.00it/s, v_num=546, train/reward=-8.21, train/loss=-0.973, val/reward=-7.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [01:53<00:00,  1.77it/s, v_num=547, train/reward=-15.0, train/loss=-5.55, val/reward=-12.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-12.7, train/loss=-3.45, val/reward=-11.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [01:48<00:00,  1.84it/s, v_num=547, train/reward=-12.3, train/loss=-3.05, val/reward=-11.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-12.0, train/loss=-2.52, val/reward=-11.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-12.3, train/loss=-4.04, val/reward=-11.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-12.3, train/loss=-5.68, val/reward=-11.3]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.8, train/loss=-4.04, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.6, train/loss=-3.06, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [01:46<00:00,  1.89it/s, v_num=547, train/reward=-11.6, train/loss=-2.24, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.6, train/loss=-5.12, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.2, train/loss=-2.28, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.7, train/loss=-3.17, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.5, train/loss=-1.84, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.7, train/loss=-2.72, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [01:45<00:00,  1.90it/s, v_num=547, train/reward=-11.5, train/loss=-2.39, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [01:48<00:00,  1.85it/s, v_num=547, train/reward=-11.8, train/loss=-3.13, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-86.6, train/loss=-106., val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [01:49<00:00,  1.83it/s, v_num=547, train/reward=-206., train/loss=-16.8, val/reward=-11.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.7, train/loss=-2.55, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-151., train/loss=-16.1, val/reward=-11.3]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-12.0, train/loss=-2.86, val/reward=-11.4] Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.5, train/loss=-3.28, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-12.0, train/loss=-3.54, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.4, train/loss=-1.95, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.5, train/loss=-2.37, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.6, train/loss=-3.08, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.5, train/loss=-2.25, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [01:45<00:00,  1.90it/s, v_num=547, train/reward=-11.9, train/loss=-2.49, val/reward=-11.3]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-11.7, train/loss=-1.95, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.9, train/loss=-2.72, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-11.9, train/loss=-2.89, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.6, train/loss=-2.46, val/reward=-11.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.3, train/loss=-1.76, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.4, train/loss=-2.30, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-11.9, train/loss=-2.52, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.6, train/loss=-2.12, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [01:47<00:00,  1.86it/s, v_num=547, train/reward=-11.5, train/loss=-1.70, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=547, train/reward=-19.2, train/loss=-43.6, val/reward=-11.2] Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=547, train/reward=-11.3, train/loss=-1.68, val/reward=-11.0]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [01:48<00:00,  1.85it/s, v_num=547, train/reward=-11.5, train/loss=-2.45, val/reward=-11.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.2, train/loss=-1.82, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [01:48<00:00,  1.85it/s, v_num=547, train/reward=-12.0, train/loss=-3.26, val/reward=-11.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.2, train/loss=-2.47, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=547, train/reward=-11.2, train/loss=-1.49, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [01:46<00:00,  1.89it/s, v_num=547, train/reward=-11.3, train/loss=-1.49, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.2, train/loss=-1.64, val/reward=-10.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [01:45<00:00,  1.89it/s, v_num=547, train/reward=-11.1, train/loss=-1.89, val/reward=-10.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.1, train/loss=-2.05, val/reward=-10.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=547, train/reward=-11.3, train/loss=-2.06, val/reward=-10.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s, v_num=547, train/reward=-11.1, train/loss=-1.84, val/reward=-10.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [01:46<00:00,  1.87it/s, v_num=547, train/reward=-11.1, train/loss=-1.84, val/reward=-10.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:47<00:00,  1.87it/s, v_num=547, train/reward=-11.1, train/loss=-1.84, val/reward=-10.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [01:07<00:00,  2.98it/s, v_num=548, train/reward=-8.95, train/loss=-1.93, val/reward=-7.95]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [00:51<00:00,  3.87it/s, v_num=548, train/reward=-8.47, train/loss=106.0, val/reward=-7.82]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [00:51<00:00,  3.88it/s, v_num=548, train/reward=-7.56, train/loss=5.960, val/reward=-7.28]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [00:52<00:00,  3.83it/s, v_num=548, train/reward=-7.52, train/loss=6.470, val/reward=-7.26]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [00:51<00:00,  3.87it/s, v_num=548, train/reward=-8.21, train/loss=-9.10, val/reward=-7.45]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [00:51<00:00,  3.89it/s, v_num=548, train/reward=-8.34, train/loss=-11.2, val/reward=-7.57]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [00:52<00:00,  3.83it/s, v_num=548, train/reward=-7.81, train/loss=3.730, val/reward=-7.41]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [00:55<00:00,  3.60it/s, v_num=548, train/reward=-15.4, train/loss=-439., val/reward=-11.8]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [00:53<00:00,  3.76it/s, v_num=548, train/reward=-15.3, train/loss=2.93e+4, val/reward=-12.7] Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [01:05<00:00,  3.06it/s, v_num=548, train/reward=-64.9, train/loss=-8.63e+3, val/reward=-3.15]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [00:51<00:00,  3.87it/s, v_num=548, train/reward=-27.1, train/loss=-2.29e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [00:50<00:00,  4.00it/s, v_num=548, train/reward=-27.2, train/loss=-2.89e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [00:50<00:00,  3.98it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [00:50<00:00,  3.96it/s, v_num=548, train/reward=-27.0, train/loss=-1.98e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.1, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [00:49<00:00,  4.01it/s, v_num=548, train/reward=-27.2, train/loss=-2.9e+3, val/reward=-26.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [00:50<00:00,  3.98it/s, v_num=548, train/reward=-27.0, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [00:50<00:00,  3.96it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [00:50<00:00,  3.96it/s, v_num=548, train/reward=-27.2, train/loss=-2.59e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-26.9, train/loss=-2.85e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [00:50<00:00,  4.00it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [00:50<00:00,  3.97it/s, v_num=548, train/reward=-27.0, train/loss=-2.57e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [00:51<00:00,  3.86it/s, v_num=548, train/reward=-27.1, train/loss=-2.28e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.1, train/loss=-1.99e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [00:50<00:00,  3.98it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [00:50<00:00,  3.98it/s, v_num=548, train/reward=-27.2, train/loss=-2.9e+3, val/reward=-26.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [00:49<00:00,  4.02it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.1, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [00:49<00:00,  4.01it/s, v_num=548, train/reward=-27.0, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.1, train/loss=-2.59e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-27.0, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [00:50<00:00,  4.00it/s, v_num=548, train/reward=-27.1, train/loss=-2.89e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [00:49<00:00,  4.03it/s, v_num=548, train/reward=-27.0, train/loss=-2.87e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-27.0, train/loss=3.83e+4, val/reward=-26.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [00:50<00:00,  3.96it/s, v_num=548, train/reward=-27.2, train/loss=-2.89e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-26.9, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-26.9, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-27.2, train/loss=-2.9e+3, val/reward=-26.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.0, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-27.2, train/loss=-2.89e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-26.9, train/loss=-2.85e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-26.9, train/loss=-2.85e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [00:50<00:00,  3.96it/s, v_num=548, train/reward=-27.2, train/loss=6.47e+4, val/reward=-26.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [00:49<00:00,  4.01it/s, v_num=548, train/reward=-27.0, train/loss=-2.86e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [00:50<00:00,  3.99it/s, v_num=548, train/reward=-27.0, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [00:49<00:00,  4.01it/s, v_num=548, train/reward=-26.9, train/loss=-2.85e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:49<00:00,  4.00it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [00:50<00:00,  3.95it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:58<00:00,  3.42it/s, v_num=548, train/reward=-27.1, train/loss=-2.88e+3, val/reward=-26.6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# POMO\n",
    "trainer_STEP5 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy5.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_POMO_C50\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_STEP5.fit(model_50)\n",
    "\n",
    "# RCPOMO\n",
    "trainer_C_STEP5 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_c5.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_RCPOMO_C50\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_C_STEP5.fit(model_c50)\n",
    "\n",
    "# REINFORCE\n",
    "trainer_R_STEP5 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_r5.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_REINFORCE_C50\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_R_STEP5.fit(model_r50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9babf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POMO: Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 86 | Mean Trained Test Cost: 5.334347\n",
      "Scale: 20 | FeasibleCounts: 31 | Mean Trained Test Cost: 7.353879\n",
      "Scale: 50 | FeasibleCounts: 46 | Mean Trained Test Cost: 15.097116\n",
      "Scale: 100 | FeasibleCounts: 86 | Mean Trained Test Cost: 25.306658\n",
      "\n",
      "RCPOMO: Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 94 | Mean Trained Test Cost: 5.148530\n",
      "Scale: 20 | FeasibleCounts: 61 | Mean Trained Test Cost: 6.982335\n",
      "Scale: 50 | FeasibleCounts: 60 | Mean Trained Test Cost: 13.203002\n",
      "Scale: 100 | FeasibleCounts: 60 | Mean Trained Test Cost: 26.687469\n",
      "\n",
      "REINFORCE: Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 75 | Mean Trained Test Cost: 6.496563\n",
      "Scale: 20 | FeasibleCounts: 4 | Mean Trained Test Cost: 9.495222\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_10500\\1936473853.py:18: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")\n"
     ]
    }
   ],
   "source": [
    "policy5 = policy5.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy5, td_tests, hard_envs)\n",
    "# print(rewards_trained)\n",
    "print(\"POMO: Trained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "policy_c5 = policy_c5.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c5, td_tests, hard_envs)\n",
    "print(\"\\nRCPOMO: Trained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost: {-rewards_c_trained[i].mean():3f}\")\n",
    "    \n",
    "policy_r5 = policy_r5.to(device)\n",
    "rewards_r_trained, num_r_valid = get_reward_and_check(policy_r5, td_tests, hard_envs)\n",
    "print(\"\\nREINFORCE: Trained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812b110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCH = 50\n",
    "BATCH_SIZE_100 = 128\n",
    "TRAIN_DATA_SIZE_100 = BATCH_SIZE_100 * 200\n",
    "VAL_DATA_SIZE_100 = BATCH_SIZE_100 * 50\n",
    "\n",
    "# POMO\n",
    "policy100 = AttentionModelPolicy(env_name=soft_envs[3].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_100 = POMO(soft_envs[3],\n",
    "                policy100,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE_100,\n",
    "                train_data_size=TRAIN_DATA_SIZE_100,\n",
    "                val_data_size=VAL_DATA_SIZE_100,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "\n",
    "# RCPOMO\n",
    "policy_c100 = AttentionModelPolicy(env_name=soft_envs[3].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_c100 = RewardConstrainedPOMO(soft_envs[3],\n",
    "                policy_c100,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE_100,\n",
    "                train_data_size=TRAIN_DATA_SIZE_100,\n",
    "                val_data_size=VAL_DATA_SIZE_100,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "\n",
    "# REINFORCE\n",
    "policy_r100 = AttentionModelPolicy(env_name=soft_envs[3].name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_r100 = REINFORCE(soft_envs[3],\n",
    "                policy_r100,\n",
    "                baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE_100,\n",
    "                train_data_size=TRAIN_DATA_SIZE_100,\n",
    "                val_data_size=VAL_DATA_SIZE_100,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b742846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [02:52<00:00,  1.16it/s, v_num=549, train/reward=-11.5, train/loss=-2.93, val/reward=-10.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [02:52<00:00,  1.16it/s, v_num=549, train/reward=-11.1, train/loss=-1.99, val/reward=-10.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [03:00<00:00,  1.11it/s, v_num=549, train/reward=-10.7, train/loss=-2.37, val/reward=-10.3]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-10.5, train/loss=-1.49, val/reward=-10.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-10.3, train/loss=-1.30, val/reward=-10.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-10.1, train/loss=-1.14, val/reward=-9.88]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-10.1, train/loss=-1.12, val/reward=-9.87] Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.96, train/loss=-0.962, val/reward=-9.76]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-10.0, train/loss=-2.16, val/reward=-9.72] Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.88, train/loss=-1.02, val/reward=-9.65] Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.79, train/loss=-1.02, val/reward=-9.58] Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.68, train/loss=-0.94, val/reward=-9.53] Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-9.65, train/loss=-0.808, val/reward=-9.50]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.69, train/loss=-1.12, val/reward=-9.51]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-9.57, train/loss=-0.907, val/reward=-9.38]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-9.55, train/loss=-0.84, val/reward=-9.36] Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.53, train/loss=-0.82, val/reward=-9.34] Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.46, train/loss=-0.923, val/reward=-9.32]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.40, train/loss=-0.789, val/reward=-9.29]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.38, train/loss=-0.817, val/reward=-9.27]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-9.39, train/loss=-1.05, val/reward=-9.24] Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.35, train/loss=-0.798, val/reward=-9.22]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-9.34, train/loss=-0.747, val/reward=-9.20]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.30, train/loss=-0.864, val/reward=-9.19]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=549, train/reward=-9.36, train/loss=-0.722, val/reward=-9.18]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.30, train/loss=-0.763, val/reward=-9.16]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=549, train/reward=-9.29, train/loss=-0.707, val/reward=-9.16]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.39, train/loss=-0.69, val/reward=-9.17] Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [03:11<00:00,  1.05it/s, v_num=549, train/reward=-9.24, train/loss=-0.76, val/reward=-9.12] Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [03:11<00:00,  1.05it/s, v_num=549, train/reward=-9.23, train/loss=-0.651, val/reward=-9.13]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-9.21, train/loss=-0.676, val/reward=-9.10]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.27, train/loss=-0.758, val/reward=-9.10]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [03:11<00:00,  1.05it/s, v_num=549, train/reward=-9.22, train/loss=-0.745, val/reward=-9.09]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [03:11<00:00,  1.05it/s, v_num=549, train/reward=-9.26, train/loss=-0.721, val/reward=-9.07]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [03:11<00:00,  1.05it/s, v_num=549, train/reward=-9.25, train/loss=-0.682, val/reward=-9.08]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.20, train/loss=-0.842, val/reward=-9.09]Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-9.21, train/loss=-0.889, val/reward=-9.07]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.18, train/loss=-0.67, val/reward=-9.04] Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.20, train/loss=-0.864, val/reward=-9.03]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.20, train/loss=-0.806, val/reward=-9.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.20, train/loss=-0.803, val/reward=-9.00]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=549, train/reward=-9.14, train/loss=-1.02, val/reward=-9.00] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=549, train/reward=-9.08, train/loss=-0.632, val/reward=-8.98]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [03:11<00:00,  1.04it/s, v_num=549, train/reward=-9.07, train/loss=-0.693, val/reward=-9.00]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [03:09<00:00,  1.05it/s, v_num=549, train/reward=-9.12, train/loss=-0.89, val/reward=-8.98] Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=549, train/reward=-9.12, train/loss=-0.736, val/reward=-8.95]Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.09, train/loss=-0.624, val/reward=-8.95]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.05, train/loss=-0.646, val/reward=-8.94]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=549, train/reward=-9.11, train/loss=-0.655, val/reward=-8.94]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=549, train/reward=-9.04, train/loss=-0.663, val/reward=-8.94]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.04, train/loss=-0.663, val/reward=-8.94]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=549, train/reward=-9.04, train/loss=-0.663, val/reward=-8.94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [03:25<00:00,  0.97it/s, v_num=550, train/reward=-25.0, train/loss=-8.07, val/reward=-22.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [03:18<00:00,  1.01it/s, v_num=550, train/reward=-22.6, train/loss=-6.39, val/reward=-20.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-23.0, train/loss=-6.26, val/reward=-21.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-21.4, train/loss=-4.23, val/reward=-20.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [03:18<00:00,  1.01it/s, v_num=550, train/reward=-20.5, train/loss=-3.92, val/reward=-20.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-20.7, train/loss=-2.97, val/reward=-20.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-20.5, train/loss=-3.00, val/reward=-19.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-20.1, train/loss=-2.68, val/reward=-19.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [03:21<00:00,  0.99it/s, v_num=550, train/reward=-20.2, train/loss=-3.98, val/reward=-19.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-19.9, train/loss=-2.92, val/reward=-19.3]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-19.3, train/loss=-3.23, val/reward=-18.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [03:21<00:00,  0.99it/s, v_num=550, train/reward=-19.6, train/loss=-3.34, val/reward=-18.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-19.7, train/loss=-1.90, val/reward=-19.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-19.0, train/loss=-2.92, val/reward=-18.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-19.2, train/loss=-2.47, val/reward=-18.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-19.4, train/loss=-5.43, val/reward=-18.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.8, train/loss=-2.22, val/reward=-18.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-18.6, train/loss=-1.75, val/reward=-18.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=550, train/reward=-19.1, train/loss=-2.82, val/reward=-18.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [03:18<00:00,  1.01it/s, v_num=550, train/reward=-19.4, train/loss=-4.61, val/reward=-18.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-18.7, train/loss=-1.73, val/reward=-18.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-20.2, train/loss=-11.7, val/reward=-18.4]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [03:13<00:00,  1.03it/s, v_num=550, train/reward=-18.4, train/loss=-1.86, val/reward=-17.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.7, train/loss=-3.23, val/reward=-18.2] Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [03:13<00:00,  1.04it/s, v_num=550, train/reward=-18.6, train/loss=-2.28, val/reward=-18.2]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-18.2, train/loss=-1.67, val/reward=-17.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [03:15<00:00,  1.03it/s, v_num=550, train/reward=-18.3, train/loss=-2.21, val/reward=-18.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-18.4, train/loss=-1.89, val/reward=-17.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [03:18<00:00,  1.01it/s, v_num=550, train/reward=-18.5, train/loss=-1.69, val/reward=-18.1] Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [03:15<00:00,  1.03it/s, v_num=550, train/reward=-18.4, train/loss=-2.25, val/reward=-17.8] Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.4, train/loss=-1.62, val/reward=-17.8] Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-17.9, train/loss=-1.50, val/reward=-17.8]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.6, train/loss=-2.18, val/reward=-18.1]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-18.0, train/loss=-1.27, val/reward=-17.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-18.9, train/loss=-4.53, val/reward=-18.0]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [03:19<00:00,  1.00it/s, v_num=550, train/reward=-19.0, train/loss=-1.87, val/reward=-18.1] Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-17.9, train/loss=-1.51, val/reward=-17.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=550, train/reward=-18.0, train/loss=-1.75, val/reward=-17.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-17.8, train/loss=-1.36, val/reward=-17.5]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [03:18<00:00,  1.01it/s, v_num=550, train/reward=-18.3, train/loss=-2.62, val/reward=-18.0] Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-18.0, train/loss=-1.46, val/reward=-17.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-18.0, train/loss=-1.42, val/reward=-17.6] Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [03:17<00:00,  1.01it/s, v_num=550, train/reward=-17.8, train/loss=-1.69, val/reward=-17.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.0, train/loss=-2.15, val/reward=-17.7] Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-17.6, train/loss=-1.65, val/reward=-17.4]Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s, v_num=550, train/reward=-17.7, train/loss=-1.36, val/reward=-17.6]Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-18.0, train/loss=-2.13, val/reward=-17.7]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s, v_num=550, train/reward=-17.7, train/loss=-1.60, val/reward=-17.5] Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [03:15<00:00,  1.02it/s, v_num=550, train/reward=-17.6, train/loss=-1.82, val/reward=-17.4]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-17.8, train/loss=-1.42, val/reward=-17.7]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-17.8, train/loss=-1.42, val/reward=-17.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s, v_num=550, train/reward=-17.8, train/loss=-1.42, val/reward=-17.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | WarmupBaseline       | 3.6 M  | train\n",
      "----------------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.482    Total estimated model params size (MB)\n",
      "128       Modules in train mode\n",
      "124       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 200/200 [01:44<00:00,  1.92it/s, v_num=551, train/reward=-14.4, train/loss=20.70, val/reward=-11.9]Callback is called\n",
      "Callback is finished\n",
      "Epoch 1: 100%|██████████| 200/200 [01:56<00:00,  1.71it/s, v_num=551, train/reward=-76.2, train/loss=-3.22e+4, val/reward=-1.04]  Callback is called\n",
      "Callback is finished\n",
      "Epoch 2: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-69.0, train/loss=-2.83e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 3: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=551, train/reward=-92.5, train/loss=-4e+4, val/reward=-1.04]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 4: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-162., train/loss=-7.64e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 5: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-123., train/loss=-5.66e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 6: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-154., train/loss=-72625.5, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 7: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=551, train/reward=-123., train/loss=-5.57e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 8: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-99.8, train/loss=-4.36e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 9: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-99.5, train/loss=-4.35e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 10: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-99.8, train/loss=-4.37e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 11: 100%|██████████| 200/200 [02:00<00:00,  1.67it/s, v_num=551, train/reward=-132., train/loss=-6.13e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 12: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-91.9, train/loss=-4.01e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 13: 100%|██████████| 200/200 [02:03<00:00,  1.63it/s, v_num=551, train/reward=-116., train/loss=-5.3e+4, val/reward=-1.04] Callback is called\n",
      "Callback is finished\n",
      "Epoch 14: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-75.9, train/loss=-3.19e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 15: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-68.4, train/loss=-2.81e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 16: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=551, train/reward=-107., train/loss=-4.72e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 17: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=551, train/reward=-92.0, train/loss=-4.02e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 18: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=551, train/reward=-91.9, train/loss=-3.98e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 19: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-84.0, train/loss=-3.63e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 20: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-123., train/loss=-5.69e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 21: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-186., train/loss=-88172.5, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 22: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=551, train/reward=-131., train/loss=-6.04e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 23: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-131., train/loss=-5.97e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 24: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-147., train/loss=-6.81e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 25: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-319., train/loss=-1.58e+5, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 26: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-84.1, train/loss=-3.59e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 27: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-91.8, train/loss=-4.01e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 28: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-84.0, train/loss=-36106.5, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 29: 100%|██████████| 200/200 [02:03<00:00,  1.62it/s, v_num=551, train/reward=-76.9, train/loss=-3.26e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 30: 100%|██████████| 200/200 [02:01<00:00,  1.65it/s, v_num=551, train/reward=-123., train/loss=-5.53e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 31: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=551, train/reward=-132., train/loss=-6.05e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 32: 100%|██████████| 200/200 [02:01<00:00,  1.65it/s, v_num=551, train/reward=-84.6, train/loss=-3.66e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 33: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-131., train/loss=-6.02e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 34: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=551, train/reward=-131., train/loss=-6.05e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 35: 100%|██████████| 200/200 [02:01<00:00,  1.65it/s, v_num=551, train/reward=-92.3, train/loss=-4.04e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 36: 100%|██████████| 200/200 [02:00<00:00,  1.66it/s, v_num=551, train/reward=-92.2, train/loss=-4.04e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 37: 100%|██████████| 200/200 [01:58<00:00,  1.68it/s, v_num=551, train/reward=-131., train/loss=-6.01e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 38: 100%|██████████| 200/200 [02:00<00:00,  1.66it/s, v_num=551, train/reward=-68.3, train/loss=-2.79e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 39: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-68.7, train/loss=-2.81e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 40: 100%|██████████| 200/200 [01:59<00:00,  1.68it/s, v_num=551, train/reward=-108., train/loss=-4.81e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 41: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-131., train/loss=-5.98e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 42: 100%|██████████| 200/200 [02:00<00:00,  1.65it/s, v_num=551, train/reward=-100., train/loss=-1.47e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 43: 100%|██████████| 200/200 [02:01<00:00,  1.65it/s, v_num=551, train/reward=-155., train/loss=-7.17e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 44: 100%|██████████| 200/200 [02:04<00:00,  1.61it/s, v_num=551, train/reward=-91.9, train/loss=-4e+4, val/reward=-1.04]   Callback is called\n",
      "Callback is finished\n",
      "Epoch 45: 100%|██████████| 200/200 [02:01<00:00,  1.65it/s, v_num=551, train/reward=-99.8, train/loss=-4.38e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 46: 100%|██████████| 200/200 [02:00<00:00,  1.66it/s, v_num=551, train/reward=-68.6, train/loss=-2.82e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 47: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-116., train/loss=-5.17e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 48: 100%|██████████| 200/200 [02:02<00:00,  1.64it/s, v_num=551, train/reward=-92.1, train/loss=-4.04e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [02:01<00:00,  1.64it/s, v_num=551, train/reward=-84.1, train/loss=-3.59e+4, val/reward=-1.04]Callback is called\n",
      "Callback is finished\n",
      "Epoch 49: 100%|██████████| 200/200 [02:02<00:00,  1.63it/s, v_num=551, train/reward=-84.1, train/loss=-3.59e+4, val/reward=-1.04]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [02:06<00:00,  1.59it/s, v_num=551, train/reward=-84.1, train/loss=-3.59e+4, val/reward=-1.04]\n"
     ]
    }
   ],
   "source": [
    "# POMO\n",
    "trainer_STEP100 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy100.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_POMO_C100\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_STEP100.fit(model_100)\n",
    "\n",
    "# RCPOMO\n",
    "trainer_C_STEP100 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_c100.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_RCPOMO_C100\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_C_STEP100.fit(model_c100)\n",
    "\n",
    "# REINFORCE\n",
    "trainer_R_STEP100 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[\n",
    "        RewardLoggingCallback(\n",
    "            policy=policy_r100.to(device),\n",
    "            test_data=td_tests,\n",
    "            env_scale=hard_envs,\n",
    "            scale = scale,\n",
    "            log_dir=\"logs\",  # Need to set the logs folder or else\n",
    "            file_name=\"SOFT_REINFORCE_C100\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "trainer_R_STEP100.fit(model_r100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f0dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POMO: Trained with Environment of C=100, S=12, EV=12\n",
      "Scale: 10 | FeasibleCounts: 45 | Mean Trained Test Cost: 7.064821\n",
      "Scale: 20 | FeasibleCounts: 1 | Mean Trained Test Cost: 6.989510\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_10500\\3784947327.py:6: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RCPOMO: Trained with Environment of C=100, S=12, EV=12\n",
      "Scale: 10 | FeasibleCounts: 44 | Mean Trained Test Cost: 7.245407\n",
      "Scale: 20 | FeasibleCounts: 1 | Mean Trained Test Cost: 9.372268\n",
      "Scale: 50 | FeasibleCounts: 1 | Mean Trained Test Cost: 17.735788\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_10500\\3784947327.py:12: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost: {-rewards_c_trained[i].mean():3f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REINFORCE: Trained with Environment of C=100, S=12, EV=12\n",
      "Scale: 10 | FeasibleCounts: 75 | Mean Trained Test Cost: 6.496563\n",
      "Scale: 20 | FeasibleCounts: 4 | Mean Trained Test Cost: 9.495222\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_10500\\3784947327.py:18: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")\n"
     ]
    }
   ],
   "source": [
    "policy100 = policy100.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy100, td_tests, hard_envs)\n",
    "# print(rewards_trained)\n",
    "print(\"POMO: Trained with Environment of C=100, S=12, EV=12\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "policy_c100 = policy_c100.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c100, td_tests, hard_envs)\n",
    "print(\"\\nRCPOMO: Trained with Environment of C=100, S=12, EV=12\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost: {-rewards_c_trained[i].mean():3f}\")\n",
    "    \n",
    "policy_r100 = policy_r100.to(device)\n",
    "rewards_r_trained, num_r_valid = get_reward_and_check(policy_r100, td_tests, hard_envs)\n",
    "print(\"\\nREINFORCE: Trained with Environment of C=100, S=12, EV=12\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_r_valid[i]} | Mean Trained Test Cost: {-rewards_r_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae3598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
