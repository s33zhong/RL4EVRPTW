{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:20.877005Z",
     "start_time": "2024-11-17T22:15:16.125128Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE, SymNCO, PPO, POMO, RewardConstrainedPOMO\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bd30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import rl4co\n",
    "print(rl4co.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec844555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\python311.zip\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\DLLs\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\n",
      "\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\Pythonwin\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\setuptools\\_vendor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.remove(r\"c:\\users\\hyosi\\onedrive\\ut\\2024 fall\\mie1666\\project\\code\\rl4evrptw\\rl4co\")\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58a04627ea0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:21.147698Z",
     "start_time": "2024-11-17T22:15:20.877005Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_10 = EVRPTWEnv(generator_params={'num_loc': 10, \n",
    "                                    'num_station': 3,\n",
    "                                    'vehicle_limit': 3,\n",
    "                                    'vehicle_speed': 5,\n",
    "                                    'max_time': 1,\n",
    "                                    'horizon': 1,\n",
    "                                    'fuel_consumption_rate': 0.25,\n",
    "                                    'inverse_recharge_rate': 0.25})\n",
    "td_10_TEST = env_10.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_20 = EVRPTWEnv(generator_params={'num_loc': 20, \n",
    "                                     'num_station': 3,\n",
    "                                     'vehicle_limit': 3,\n",
    "                                     'vehicle_speed': 5,\n",
    "                                     'max_time': 1,\n",
    "                                     'horizon': 1,\n",
    "                                     'fuel_consumption_rate': 0.25,\n",
    "                                     'inverse_recharge_rate': 0.25})\n",
    "td_20_TEST = env_20.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_50 = EVRPTWEnv(generator_params={'num_loc': 50, \n",
    "                                     'num_station': 6,\n",
    "                                     'vehicle_limit': 6,\n",
    "                                     'vehicle_speed': 5,\n",
    "                                     'max_time': 1,\n",
    "                                     'horizon': 1,\n",
    "                                     'fuel_consumption_rate': 0.25,\n",
    "                                     'inverse_recharge_rate': 0.25})\n",
    "td_50_TEST = env_50.reset(batch_size=[100]).to(device)\n",
    "\n",
    "\n",
    "enforce_reproducibility(0)\n",
    "env_100 = EVRPTWEnv(generator_params={'num_loc': 100,\n",
    "                                    'num_station': 12,\n",
    "                                    'vehicle_limit': 12,\n",
    "                                    'vehicle_speed': 5,\n",
    "                                    'max_time': 1,\n",
    "                                    'horizon': 1,\n",
    "                                    'fuel_consumption_rate': 0.25,\n",
    "                                    'inverse_recharge_rate': 0.25})\n",
    "td_100_TEST = env_100.reset(batch_size=[100]).to(device)\n",
    "\n",
    "MAX_EPOCH = 50\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "# MAX_EPOCH = 10\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b92290e4554f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:25.146517Z",
     "start_time": "2024-11-17T22:15:24.187177Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy1 = AttentionModelPolicy(env_name=env_10.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy2 = AttentionModelPolicy(env_name=env_20.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy5 = AttentionModelPolicy(env_name=env_50.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "\n",
    "model_10 = POMO(env_10,\n",
    "                policy1,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_20 = POMO(env_20,\n",
    "                policy2,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_50 = POMO(env_50,\n",
    "                policy5,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy_c1 = AttentionModelPolicy(env_name=env_10.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_c2 = AttentionModelPolicy(env_name=env_20.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "policy_c5 = AttentionModelPolicy(env_name=env_50.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "\n",
    "model_constrained_10 = RewardConstrainedPOMO(env_10,\n",
    "                policy_c1,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "\n",
    "model_constrained_20 = RewardConstrainedPOMO(env_20,\n",
    "                policy_c2,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n",
    "model_constrained_50 = RewardConstrainedPOMO(env_50,\n",
    "                policy_c5,\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                \"weight_decay\": 1e-6})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6114690c450fabd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:27.620347Z",
     "start_time": "2024-11-17T22:15:26.115913Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 10 | Mean Untrained Test Cost: 8.261545\n",
      "Scale: 20 | Mean Untrained Test Cost: 15.953616\n",
      "Scale: 50 | Mean Untrained Test Cost: 37.462704\n",
      "Scale: 100 | Mean Untrained Test Cost: 69.678444\n"
     ]
    }
   ],
   "source": [
    "# Greedy rollouts over untrained policy\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "policy = policy1.to(device)\n",
    "out_10 = policy(td_10_TEST.clone(), env=env_10, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_20 = policy(td_20_TEST.clone(), env=env_20, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_50 = policy(td_50_TEST.clone(), env=env_50, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "out_100 = policy(td_100_TEST.clone(), env=env_100, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "\n",
    "rewards_untrained_10 = out_10['reward'].cpu().numpy()\n",
    "rewards_untrained_20 = out_20['reward'].cpu().numpy()\n",
    "rewards_untrained_50 = out_50['reward'].cpu().numpy()\n",
    "rewards_untrained_100 = out_100['reward'].cpu().numpy()\n",
    "rewards = [rewards_untrained_10, rewards_untrained_20, rewards_untrained_50, rewards_untrained_100]\n",
    "# print(f\"Scale: 10 | Mean Untrained Test Cost: {-rewards_untrained_10.mean():3f}\")\n",
    "scale = [10, 20, 50, 100]\n",
    "for i in range(4):\n",
    "    print(f\"Scale: {scale[i]} | Mean Untrained Test Cost: {-rewards[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f7044d2edd277c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:16:06.321995Z",
     "start_time": "2024-11-17T22:16:06.103791Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del out_10, out_20, out_50, out_100\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c64219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(rewards, raw=False):\n",
    "    valid_rewards = []\n",
    "    for reward in rewards:\n",
    "        if -reward > 1000:\n",
    "            pass\n",
    "        else:\n",
    "            valid_rewards.append(reward)\n",
    "    return np.array(valid_rewards)\n",
    "\n",
    "def get_reward_and_check(policy, test_data, env_scale):\n",
    "    rewards_trained = []\n",
    "    rewards_trained_for_fesibility = []\n",
    "    num_valids = []\n",
    "    for td_i, env_i in zip(test_data, env_scale):\n",
    "        out = policy(td_i.clone(), \n",
    "                    env=env_i, \n",
    "                    phase=\"test\", \n",
    "                    feasibility_check=True, \n",
    "                    decode_type=\"greedy\", \n",
    "                    return_actions=True)\n",
    "        valid_out = validity_check(out['reward'].cpu().numpy())\n",
    "        rewards_trained.append(valid_out)\n",
    "        num_valids.append(len(valid_out))\n",
    "\n",
    "    return rewards_trained, num_valids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83febd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:20<00:00,  9.99it/s, v_num=122, train/reward=-4.43, train/loss=-0.045, val/reward=-4.53] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:20<00:00,  9.93it/s, v_num=122, train/reward=-4.43, train/loss=-0.045, val/reward=-4.53]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:20<00:00,  9.72it/s, v_num=123, train/reward=-4.54, train/loss=-0.0372, val/reward=-4.53]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:20<00:00,  9.67it/s, v_num=123, train/reward=-4.54, train/loss=-0.0372, val/reward=-4.53]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP1.fit(model_10)\n",
    "\n",
    "trainer_C_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP1.fit(model_constrained_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d474c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=10, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.346294\n",
      "Scale: 20 | FeasibleCounts: 99 | Mean Trained Test Cost: 7.185377\n",
      "Scale: 50 | FeasibleCounts: 73 | Mean Trained Test Cost: 14.895159\n",
      "Scale: 100 | FeasibleCounts: 42 | Mean Trained Test Cost: 26.661594\n",
      "\n",
      "Trained with Environment of C=10, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.319823\n",
      "Scale: 20 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 7.080900\n",
      "Scale: 50 | FeasibleCounts: 74 | Mean Trained Test Cost (Constrained): 14.878680\n",
      "Scale: 100 | FeasibleCounts: 46 | Mean Trained Test Cost (Constrained): 26.887674\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy1 = policy1.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy1, td_scale_test, env_scale)\n",
    "# print(rewards_trained)\n",
    "print(\"Trained with Environment of C=10, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "policy_c1 = policy_c1.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c1, td_scale_test, env_scale)\n",
    "print(\"\\nTrained with Environment of C=10, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98a7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_trained, rewards_c_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5720b863b4964746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T20:08:25.046679Z",
     "start_time": "2024-11-16T19:21:39.623025Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:34<00:00,  5.85it/s, v_num=124, train/reward=-6.91, train/loss=-0.117, val/reward=-6.90] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:34<00:00,  5.83it/s, v_num=124, train/reward=-6.91, train/loss=-0.117, val/reward=-6.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:34<00:00,  5.88it/s, v_num=125, train/reward=-6.92, train/loss=-0.104, val/reward=-6.89] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [00:34<00:00,  5.86it/s, v_num=125, train/reward=-6.92, train/loss=-0.104, val/reward=-6.89]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP2.fit(model_20)\n",
    "\n",
    "trainer_C_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP2.fit(model_constrained_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0778b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=20, S=3, EV=3\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.430041\n",
      "Scale: 20 | FeasibleCounts: 100 | Mean Trained Test Cost: 6.637908\n",
      "Scale: 50 | FeasibleCounts: 83 | Mean Trained Test Cost: 13.602371\n",
      "Scale: 100 | FeasibleCounts: 34 | Mean Trained Test Cost: 26.428389\n",
      "\n",
      "Trained with Environment of C=20, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.387401\n",
      "Scale: 20 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 6.628117\n",
      "Scale: 50 | FeasibleCounts: 85 | Mean Trained Test Cost (Constrained): 13.663721\n",
      "Scale: 100 | FeasibleCounts: 10 | Mean Trained Test Cost (Constrained): 27.547607\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy2 = policy2.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy2, td_scale_test, env_scale)\n",
    "print(\"Trained with Environment of C=20, S=3, EV=3\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "policy_c2 = policy_c2.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c2, td_scale_test, env_scale)\n",
    "print(\"\\nTrained with Environment of C=20, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56417938c52d941f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T00:29:59.512536Z",
     "start_time": "2024-11-17T00:29:59.151700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del rewards_trained, rewards_c_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400779ce7b643d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:13:44.513107Z",
     "start_time": "2024-11-16T20:08:26.556833Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:33<00:00,  2.15it/s, v_num=126, train/reward=-13.0, train/loss=-0.338, val/reward=-12.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:33<00:00,  2.14it/s, v_num=126, train/reward=-13.0, train/loss=-0.338, val/reward=-12.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:28<00:00,  2.26it/s, v_num=127, train/reward=-13.1, train/loss=-0.355, val/reward=-12.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 200/200 [01:28<00:00,  2.26it/s, v_num=127, train/reward=-13.1, train/loss=-0.355, val/reward=-12.8]\n"
     ]
    }
   ],
   "source": [
    "trainer_STEP3 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP3.fit(model_50)\n",
    "\n",
    "trainer_c_STEP3 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_c_STEP3.fit(model_constrained_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7115537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost: 4.685273\n",
      "Scale: 20 | FeasibleCounts: 100 | Mean Trained Test Cost: 6.819117\n",
      "Scale: 50 | FeasibleCounts: 90 | Mean Trained Test Cost: 12.411656\n",
      "Scale: 100 | FeasibleCounts: 64 | Mean Trained Test Cost: 21.870928\n",
      "\n",
      "Trained with Environment of C=50, S=6, EV=6\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.646067\n",
      "Scale: 20 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 6.879727\n",
      "Scale: 50 | FeasibleCounts: 90 | Mean Trained Test Cost (Constrained): 12.355714\n",
      "Scale: 100 | FeasibleCounts: 63 | Mean Trained Test Cost (Constrained): 22.047026\n"
     ]
    }
   ],
   "source": [
    "td_scale_test = [td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST]\n",
    "env_scale = [env_10, env_20, env_50, env_100]\n",
    "scale = [10, 20, 50, 100]\n",
    "\n",
    "\n",
    "policy5 = policy5.to(device)\n",
    "rewards_trained, num_valid = get_reward_and_check(policy5, td_scale_test, env_scale)\n",
    "print(\"Trained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_valid[i]} | Mean Trained Test Cost: {-rewards_trained[i].mean():3f}\")\n",
    "\n",
    "\n",
    "policy_c5 = policy_c5.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c5, td_scale_test, env_scale)\n",
    "print(\"\\nTrained with Environment of C=50, S=6, EV=6\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5dce37ab6e92f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T22:13:45.762121Z",
     "start_time": "2024-11-16T22:13:44.513107Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del rewards_trained, rewards_c_trained, num_valid\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
