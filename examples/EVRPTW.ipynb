{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:23:53.066033Z",
     "start_time": "2024-10-23T00:23:48.477022Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "env = EVRPTWEnv(generator_params={'num_loc': 5, \n",
    "                                  'num_station': 1,\n",
    "                                  'vehicle_limit': 3,\n",
    "                                  'vehicle_capacity': 2000,\n",
    "                                  'max_time': 480,\n",
    "                                  \"horizon\": 20000,\n",
    "                                  'capacity': 2000,\n",
    "                                  'max_fuel': 1000,\n",
    "                                  'scale': True})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:24:27.139858Z",
     "start_time": "2024-10-23T00:24:26.284055Z"
    }
   },
   "id": "e58a04627ea0a434",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = AttentionModelPolicy(env_name=env.name,\n",
    "                              embed_dim=64,\n",
    "                              num_encoder_layers=3,\n",
    "                              num_heads=4,\n",
    "                              )\n",
    "\n",
    "# RL Model: REINFORCE and greedy rollout baseline\n",
    "model = REINFORCE(env,\n",
    "                  policy,\n",
    "                  baseline=\"rollout\",\n",
    "                  batch_size=64,\n",
    "                  train_data_size=10_000,\n",
    "                  val_data_size=1_000,\n",
    "                  optimizer_kwargs={\"lr\": 1e-4},\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:24:53.008022Z",
     "start_time": "2024-10-23T00:24:52.872658Z"
    }
   },
   "id": "e2b92290e4554f5c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions are:  tensor([[1, 4, 2, 5, 0, 3, 0]])\n",
      "To be implemented.\n",
      "Problem 1 | Cost: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Greedy rollouts over untrained policy\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "td_init = env.reset(batch_size=[1]).to(device)\n",
    "policy = policy.to(device)\n",
    "out = policy(td_init, env=env, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "\n",
    "actions_untrained = out['actions'].cpu().detach()\n",
    "rewards_untrained = out['reward'].cpu().detach()\n",
    "\n",
    "for i in range(1):\n",
    "    print(f\"Problem {i+1} | Cost: {-rewards_untrained[i]:.3f}\")\n",
    "    # env.render(td_init[i], actions_untrained[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:26:15.409084Z",
     "start_time": "2024-10-23T00:26:15.263690Z"
    }
   },
   "id": "6114690c450fabd2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = RL4COTrainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:24:54.971048Z",
     "start_time": "2024-10-23T00:24:54.807674Z"
    }
   },
   "id": "bf2fe2a662bdceb0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Mask:  torch.Size([64, 7])\n",
      "Attention Mask:  torch.Size([64, 7])\n",
      "Attention Mask:  torch.Size([64, 7])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Logits contain NaNs",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model)\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\utils\\trainer.py:146\u001B[0m, in \u001B[0;36mRL4COTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    141\u001B[0m         log\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    142\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOverriding gradient_clip_val to None for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautomatic_optimization=False\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m models\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    143\u001B[0m         )\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_clip_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 146\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    147\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m    148\u001B[0m     train_dataloaders\u001B[38;5;241m=\u001B[39mtrain_dataloaders,\n\u001B[0;32m    149\u001B[0m     val_dataloaders\u001B[38;5;241m=\u001B[39mval_dataloaders,\n\u001B[0;32m    150\u001B[0m     datamodule\u001B[38;5;241m=\u001B[39mdatamodule,\n\u001B[0;32m    151\u001B[0m     ckpt_path\u001B[38;5;241m=\u001B[39mckpt_path,\n\u001B[0;32m    152\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 544\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_and_handle_interrupt(\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001B[0;32m    546\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    576\u001B[0m     ckpt_path,\n\u001B[0;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    579\u001B[0m )\n\u001B[1;32m--> 580\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run(model, ckpt_path\u001B[38;5;241m=\u001B[39mckpt_path)\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:949\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    946\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: preparing data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    947\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mprepare_data()\n\u001B[1;32m--> 949\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_setup_hook(\u001B[38;5;28mself\u001B[39m)  \u001B[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001B[39;00m\n\u001B[0;32m    950\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: configuring model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    951\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_configure_model(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:94\u001B[0m, in \u001B[0;36m_call_setup_hook\u001B[1;34m(trainer)\u001B[0m\n\u001B[0;32m     92\u001B[0m     _call_lightning_datamodule_hook(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetup\u001B[39m\u001B[38;5;124m\"\u001B[39m, stage\u001B[38;5;241m=\u001B[39mfn)\n\u001B[0;32m     93\u001B[0m _call_callback_hooks(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetup\u001B[39m\u001B[38;5;124m\"\u001B[39m, stage\u001B[38;5;241m=\u001B[39mfn)\n\u001B[1;32m---> 94\u001B[0m _call_lightning_module_hook(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetup\u001B[39m\u001B[38;5;124m\"\u001B[39m, stage\u001B[38;5;241m=\u001B[39mfn)\n\u001B[0;32m     96\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost_setup\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:157\u001B[0m, in \u001B[0;36m_call_lightning_module_hook\u001B[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 157\u001B[0m     output \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[0;32m    160\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\common\\base.py:155\u001B[0m, in \u001B[0;36mRL4COLitModule.setup\u001B[1;34m(self, stage)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msetup_loggers()\n\u001B[1;32m--> 155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_setup_hook()\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\reinforce.py:119\u001B[0m, in \u001B[0;36mREINFORCE.post_setup_hook\u001B[1;34m(self, stage)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost_setup_hook\u001B[39m(\u001B[38;5;28mself\u001B[39m, stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# Make baseline taking model itself and train_dataloader from model as input\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbaseline\u001B[38;5;241m.\u001B[39msetup(\n\u001B[0;32m    120\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy,\n\u001B[0;32m    121\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv,\n\u001B[0;32m    122\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_batch_size,\n\u001B[0;32m    123\u001B[0m         device\u001B[38;5;241m=\u001B[39mget_lightning_device(\u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    124\u001B[0m         dataset_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_cfg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_data_size\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    125\u001B[0m     )\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:117\u001B[0m, in \u001B[0;36mWarmupBaseline.setup\u001B[1;34m(self, *args, **kw)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msetup\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbaseline\u001B[38;5;241m.\u001B[39msetup(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:174\u001B[0m, in \u001B[0;36mRolloutBaseline.setup\u001B[1;34m(self, *args, **kw)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msetup\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m--> 174\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_policy(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:187\u001B[0m, in \u001B[0;36mRolloutBaseline._update_policy\u001B[1;34m(self, policy, env, batch_size, device, dataset_size, dataset)\u001B[0m\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mdataset(batch_size\u001B[38;5;241m=\u001B[39m[dataset_size])\n\u001B[0;32m    185\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating baseline policy on evaluation dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbl_vals \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 187\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrollout(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy, env, batch_size, device, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    188\u001B[0m )\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbl_vals\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:242\u001B[0m, in \u001B[0;36mRolloutBaseline.rollout\u001B[1;34m(self, policy, env, batch_size, device, dataset)\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m policy(batch, env, decode_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreedy\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreward\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    240\u001B[0m dl \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, collate_fn\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mcollate_fn)\n\u001B[1;32m--> 242\u001B[0m rewards \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([eval_policy(batch) \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dl], \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m rewards\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:242\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m policy(batch, env, decode_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreedy\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreward\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    240\u001B[0m dl \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, collate_fn\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mcollate_fn)\n\u001B[1;32m--> 242\u001B[0m rewards \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([eval_policy(batch) \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dl], \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m rewards\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\rl\\reinforce\\baselines.py:238\u001B[0m, in \u001B[0;36mRolloutBaseline.rollout.<locals>.eval_policy\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[0;32m    237\u001B[0m     batch \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset(batch\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[1;32m--> 238\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m policy(batch, env, decode_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreedy\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreward\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\common\\constructive\\base.py:230\u001B[0m, in \u001B[0;36mConstructivePolicy.forward\u001B[1;34m(self, td, env, phase, calc_reward, return_actions, return_entropy, return_hidden, return_init_embeds, return_sum_log_likelihood, actions, max_steps, **decoding_kwargs)\u001B[0m\n\u001B[0;32m    228\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m td[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mall():\n\u001B[1;32m--> 230\u001B[0m     logits, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(td, hidden, num_starts)\n\u001B[0;32m    231\u001B[0m     td \u001B[38;5;241m=\u001B[39m decode_strategy\u001B[38;5;241m.\u001B[39mstep(\n\u001B[0;32m    232\u001B[0m         logits,\n\u001B[0;32m    233\u001B[0m         mask,\n\u001B[0;32m    234\u001B[0m         td,\n\u001B[0;32m    235\u001B[0m         action\u001B[38;5;241m=\u001B[39mactions[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, step] \u001B[38;5;28;01mif\u001B[39;00m actions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    236\u001B[0m     )\n\u001B[0;32m    237\u001B[0m     td \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(td)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\zoo\\am\\decoder.py:191\u001B[0m, in \u001B[0;36mAttentionModelDecoder.forward\u001B[1;34m(self, td, cached, num_starts)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# Compute logits\u001B[39;00m\n\u001B[0;32m    190\u001B[0m mask \u001B[38;5;241m=\u001B[39m td[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maction_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 191\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpointer(glimpse_q, glimpse_k, glimpse_v, logit_k, mask)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;66;03m# Now we need to reshape the logits and mask to [B*S,N,...] is num_starts > 1 without dynamic embeddings\u001B[39;00m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# note that rearranging order is important here\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_starts \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_dyn_emb_multi_start:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\rl4co\\rl4co\\models\\nn\\attention.py:291\u001B[0m, in \u001B[0;36mPointerAttention.forward\u001B[1;34m(self, query, key, value, logit_key, attn_mask)\u001B[0m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# print(logits)\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_nan:\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misnan(logits)\u001B[38;5;241m.\u001B[39many(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLogits contain NaNs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m logits\n",
      "\u001B[1;31mAssertionError\u001B[0m: Logits contain NaNs"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T00:24:56.478455Z",
     "start_time": "2024-10-23T00:24:55.724992Z"
    }
   },
   "id": "a5cc449045b5be22",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Greedy rollouts over trained model (same states as previous plot)\n",
    "policy = model.policy.to(device)\n",
    "out = policy(td_init.clone(), phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "actions_trained = out['actions'].cpu().detach()\n",
    "rewards_trained = out['reward'].cpu().detach()\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "for i, td in enumerate(td_init):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(11,5))\n",
    "    env.render(td, actions_untrained[i], ax=axs[0])\n",
    "    env.render(td, actions_trained[i], ax=axs[1])\n",
    "    axs[0].set_title(f\"Untrained | Cost = {-rewards_untrained[i].item():.3f}\")\n",
    "    axs[1].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9576452c7df96ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "actions_trained"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167263cba1e49ede",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38a3fd9d5c8475c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
