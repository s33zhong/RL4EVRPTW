{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:20.877005Z",
     "start_time": "2024-11-17T22:15:16.125128Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE, SymNCO, PPO, POMO, RewardConstrainedPOMO\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bd30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import rl4co\n",
    "print(rl4co.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec844555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\python311.zip\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\DLLs\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\n",
      "\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\Pythonwin\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\setuptools\\_vendor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.remove(r\"c:\\users\\hyosi\\onedrive\\ut\\2024 fall\\mie1666\\project\\code\\rl4evrptw\\rl4co\")\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58a04627ea0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:21.147698Z",
     "start_time": "2024-11-17T22:15:20.877005Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "# hard_env_10, hard_env_20, hard_env_50, hard_env_100 = hard_envs[0], hard_envs[1], hard_envs[2], hard_envs[3]\n",
    "# td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST = td_tests[0], td_tests[1], td_tests[2], td_tests[3]\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "# soft_env_10, soft_env_20, soft_env_50, soft_env_100 = soft_envs[0], soft_envs[1], soft_envs[2], soft_envs[3]\n",
    "\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 5\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab8da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "soft_policies = []\n",
    "for soft_env in soft_envs:\n",
    "    soft_policy = AttentionModelPolicy(env_name=soft_env.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "    soft_policies.append(soft_policy)\n",
    "\n",
    "soft_models = []\n",
    "for soft_env, soft_policy in zip(soft_envs, soft_policies):\n",
    "    soft_model = RewardConstrainedPOMO(soft_env,\n",
    "                soft_policy,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "    soft_models.append(soft_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f70109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(rewards, infeasibility, soft=False):\n",
    "    valid_rewards = []\n",
    "    if soft:\n",
    "        for infeasible, reward in zip(infeasibility, rewards):\n",
    "            if -reward > 1000 or infeasible:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    else:\n",
    "        for reward in  rewards:\n",
    "            if -reward > 1000:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    return np.array(valid_rewards)\n",
    "\n",
    "\n",
    "def get_reward_and_check(policy, test_data, env_scale, soft=False):\n",
    "    rewards_trained = []\n",
    "    num_valids = []\n",
    "    for td_i, env_i in zip(test_data, env_scale):\n",
    "        out = policy(td_i.clone(), \n",
    "                    env=env_i, \n",
    "                    phase=\"test\", \n",
    "                    feasibility_check=True, \n",
    "                    decode_type=\"greedy\", \n",
    "                    return_actions=True)\n",
    "        valid_out = validity_check(out['reward'].cpu().numpy(), out[\"infeasibility\"], soft=soft)\n",
    "        rewards_trained.append(valid_out) \n",
    "        if soft:\n",
    "            num_feasible = td_i.batch_size - sum(out[\"infeasibility\"]).cpu().numpy()\n",
    "            num_valids.append(len(valid_out)+num_feasible)\n",
    "        else:\n",
    "            num_valids.append(len(valid_out))       \n",
    "    return rewards_trained, num_valids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f65427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:21<00:00,  9.34it/s, v_num=340, train/reward=-3.66, train/loss=-0.178, val/reward=-3.65]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:21<00:00,  9.28it/s, v_num=340, train/reward=-3.66, train/loss=-0.178, val/reward=-3.65]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:19<00:00, 10.31it/s, v_num=341, train/reward=-4.61, train/loss=-0.0642, val/reward=-4.54]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:19<00:00, 10.25it/s, v_num=341, train/reward=-4.61, train/loss=-0.0642, val/reward=-4.54]\n"
     ]
    }
   ],
   "source": [
    "# Soft training (w/o masking)\n",
    "trainer_C_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP.fit(soft_models[0])\n",
    "\n",
    "# Hard training (w/ masking)\n",
    "hard_model = POMO(\n",
    "                hard_envs[0],\n",
    "                soft_policies[0],\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6}\n",
    "            )\n",
    "\n",
    "trainer_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP.fit(hard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f89d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=10, S=3, EV=3 (Soft -> Hard)\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.238647\n",
      "Scale: 20 | FeasibleCounts: 96 | Mean Trained Test Cost (Constrained): 6.536129\n",
      "Scale: 50 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 13.090445\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 23.495939\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy = hard_model.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=10, S=3, EV=3 (Soft -> Hard)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f95c53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid, hard_model, policy, trainer_STEP, trainer_C_STEP\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4902f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:37<00:00,  5.34it/s, v_num=342, train/reward=-5.64, train/loss=-0.527, val/reward=-5.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:37<00:00,  5.32it/s, v_num=342, train/reward=-5.64, train/loss=-0.527, val/reward=-5.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:32<00:00,  6.12it/s, v_num=343, train/reward=-7.07, train/loss=-0.163, val/reward=-6.92]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [00:32<00:00,  6.10it/s, v_num=343, train/reward=-7.07, train/loss=-0.163, val/reward=-6.92]\n"
     ]
    }
   ],
   "source": [
    "# Soft training (w/o masking)\n",
    "trainer_C_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP.fit(soft_models[1])\n",
    "\n",
    "# Hard training (w/ masking)\n",
    "hard_model = POMO(\n",
    "                hard_envs[1],\n",
    "                soft_policies[1],\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6}\n",
    "            )\n",
    "\n",
    "trainer_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP.fit(hard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6caf3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=20, S=3, EV=3 (Soft -> Hard)\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.296908\n",
      "Scale: 20 | FeasibleCounts: 98 | Mean Trained Test Cost (Constrained): 6.431041\n",
      "Scale: 50 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 12.404896\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 25.360874\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy = hard_model.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=20, S=3, EV=3 (Soft -> Hard)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed1af801",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid, hard_model, policy, trainer_STEP, trainer_C_STEP\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df306f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [02:00<00:00,  1.66it/s, v_num=344, train/reward=-10.5, train/loss=-1.42, val/reward=-10.2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [02:00<00:00,  1.66it/s, v_num=344, train/reward=-10.5, train/loss=-1.42, val/reward=-10.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [01:28<00:00,  2.26it/s, v_num=345, train/reward=-12.3, train/loss=-0.544, val/reward=-12.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [01:28<00:00,  2.26it/s, v_num=345, train/reward=-12.3, train/loss=-0.544, val/reward=-12.1]\n"
     ]
    }
   ],
   "source": [
    "# Soft training (w/o masking)\n",
    "trainer_C_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP.fit(soft_models[2])\n",
    "\n",
    "# Hard training (w/ masking)\n",
    "hard_model = POMO(\n",
    "                hard_envs[2],\n",
    "                soft_policies[2],\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6}\n",
    "            )\n",
    "\n",
    "trainer_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP.fit(hard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e616c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=50, S=6, EV=6 (Soft -> Hard)\n",
      "Scale: 10 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 4.565583\n",
      "Scale: 20 | FeasibleCounts: 86 | Mean Trained Test Cost (Constrained): 6.509837\n",
      "Scale: 50 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 11.726592\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 20.970861\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy = hard_model.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=50, S=6, EV=6 (Soft -> Hard)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e0091e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid, hard_model, policy, trainer_STEP, trainer_C_STEP\n",
    "del hard_envs, soft_envs, td_tests\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d624ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 5\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168527d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [03:03<00:00,  1.09it/s, v_num=347, train/reward=-18.1, train/loss=-3.22, val/reward=-17.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [03:03<00:00,  1.09it/s, v_num=347, train/reward=-18.1, train/loss=-3.22, val/reward=-17.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [02:22<00:00,  1.40it/s, v_num=348, train/reward=-20.0, train/loss=-1.76, val/reward=-19.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 200/200 [02:23<00:00,  1.40it/s, v_num=348, train/reward=-20.0, train/loss=-1.76, val/reward=-19.5]\n"
     ]
    }
   ],
   "source": [
    "# Soft training (w/o masking)\n",
    "trainer_C_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP.fit(soft_models[3])\n",
    "\n",
    "# Hard training (w/ masking)\n",
    "hard_model = POMO(\n",
    "                hard_envs[3],\n",
    "                soft_policies[3],\n",
    "                # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6}\n",
    "            )\n",
    "\n",
    "trainer_STEP = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_STEP.fit(hard_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76561b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=100, S=12, EV=12 (Soft -> Hard)\n",
      "Scale: 10 | FeasibleCounts: 99 | Mean Trained Test Cost (Constrained): 4.621468\n",
      "Scale: 20 | FeasibleCounts: 77 | Mean Trained Test Cost (Constrained): 6.787745\n",
      "Scale: 50 | FeasibleCounts: 99 | Mean Trained Test Cost (Constrained): 12.109081\n",
      "Scale: 100 | FeasibleCounts: 100 | Mean Trained Test Cost (Constrained): 19.127737\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy = hard_model.to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=100, S=12, EV=12 (Soft -> Hard)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581b2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
