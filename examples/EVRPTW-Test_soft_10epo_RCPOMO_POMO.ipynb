{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:20.877005Z",
     "start_time": "2024-11-17T22:15:16.125128Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rl4co.envs import CVRPTWEnv, EVRPTWEnv \n",
    "from rl4co.models import AttentionModelPolicy, REINFORCE, SymNCO, PPO, POMO, RewardConstrainedPOMO\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bd30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\rl4co\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import rl4co\n",
    "print(rl4co.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec844555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\python311.zip\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\DLLs\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\n",
      "\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\Pythonwin\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\setuptools\\_vendor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.remove(r\"c:\\users\\hyosi\\onedrive\\ut\\2024 fall\\mie1666\\project\\code\\rl4evrptw\\rl4co\")\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58a04627ea0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:15:21.147698Z",
     "start_time": "2024-11-17T22:15:20.877005Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.7. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.7. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\torchrl\\data\\tensor_specs.py:5464: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.7. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "# hard_env_10, hard_env_20, hard_env_50, hard_env_100 = hard_envs[0], hard_envs[1], hard_envs[2], hard_envs[3]\n",
    "# td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST = td_tests[0], td_tests[1], td_tests[2], td_tests[3]\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "# soft_env_10, soft_env_20, soft_env_50, soft_env_100 = soft_envs[0], soft_envs[1], soft_envs[2], soft_envs[3]\n",
    "\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab8da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "soft_policies = []\n",
    "for soft_env in soft_envs:\n",
    "    soft_policy = AttentionModelPolicy(env_name=soft_env.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "    soft_policies.append(soft_policy)\n",
    "\n",
    "soft_models = []\n",
    "for soft_env, soft_policy in zip(soft_envs, soft_policies):\n",
    "    soft_model = RewardConstrainedPOMO(soft_env,\n",
    "                soft_policy,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "    soft_models.append(soft_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f70109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(rewards, infeasibility, soft=False):\n",
    "    valid_rewards = []\n",
    "    if soft:\n",
    "        for infeasible, reward in zip(infeasibility, rewards):\n",
    "            if -reward > 1000 or infeasible:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    else:\n",
    "        for reward in  rewards:\n",
    "            if -reward > 1000:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    return np.array(valid_rewards)\n",
    "\n",
    "\n",
    "def get_reward_and_check(policy, test_data, env_scale, soft=False):\n",
    "    rewards_trained = []\n",
    "    num_valids = []\n",
    "    for td_i, env_i in zip(test_data, env_scale):\n",
    "        out = policy(td_i.clone(), \n",
    "                    env=env_i, \n",
    "                    phase=\"test\", \n",
    "                    feasibility_check=True, \n",
    "                    decode_type=\"greedy\", \n",
    "                    return_actions=True)\n",
    "        valid_out = validity_check(out['reward'].cpu().numpy(), out[\"infeasibility\"], soft=soft)\n",
    "        rewards_trained.append(valid_out) \n",
    "        if soft:\n",
    "            num_feasible = td_i.batch_size - sum(out[\"infeasibility\"]).cpu().numpy()\n",
    "            num_valids.append(len(valid_out)+num_feasible)\n",
    "        else:\n",
    "            num_valids.append(len(valid_out))       \n",
    "    return rewards_trained, num_valids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f65427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:22<00:00,  9.00it/s, v_num=362, train/reward=-3.59, train/loss=-0.126, val/reward=-3.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:22<00:00,  8.95it/s, v_num=362, train/reward=-3.59, train/loss=-0.126, val/reward=-3.60]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP1.fit(soft_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f89d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=10, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 70 | Mean Trained Test Cost (Constrained): 6.631802\n",
      "Scale: 20 | FeasibleCounts: 13 | Mean Trained Test Cost (Constrained): 7.999508\n",
      "Scale: 50 | FeasibleCounts: 19 | Mean Trained Test Cost (Constrained): 15.868690\n",
      "Scale: 100 | FeasibleCounts: 49 | Mean Trained Test Cost (Constrained): 29.106329\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c0 = soft_models[0].to(device)\n",
    "# Validity check is done with hard envs\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c0, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=10, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95c53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4902f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:38<00:00,  5.26it/s, v_num=363, train/reward=-5.40, train/loss=-0.392, val/reward=-5.31]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:38<00:00,  5.24it/s, v_num=363, train/reward=-5.40, train/loss=-0.392, val/reward=-5.31]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP1.fit(soft_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6caf3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=20, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 45 | Mean Trained Test Cost (Constrained): 6.912762\n",
      "Scale: 20 | FeasibleCounts: 1 | Mean Trained Test Cost (Constrained): 8.723574\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost (Constrained): nan\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost (Constrained): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_13944\\1160707197.py:7: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c1 = soft_models[1].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c1, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=20, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1af801",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df306f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:56<00:00,  1.72it/s, v_num=323, train/reward=-10.3, train/loss=-1.81, val/reward=-9.97]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:56<00:00,  1.71it/s, v_num=323, train/reward=-10.3, train/loss=-1.81, val/reward=-9.97]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP2.fit(soft_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e616c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=50, S=6, EV=6 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 86 | Mean Trained Test Cost (Constrained): 5.373333\n",
      "Scale: 20 | FeasibleCounts: 23 | Mean Trained Test Cost (Constrained): 8.215921\n",
      "Scale: 50 | FeasibleCounts: 14 | Mean Trained Test Cost (Constrained): 15.220946\n",
      "Scale: 100 | FeasibleCounts: 18 | Mean Trained Test Cost (Constrained): 31.732924\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c2 = soft_models[2].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c2, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=50, S=6, EV=6 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d624ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "# hard_env_10, hard_env_20, hard_env_50, hard_env_100 = hard_envs[0], hard_envs[1], hard_envs[2], hard_envs[3]\n",
    "# td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST = td_tests[0], td_tests[1], td_tests[2], td_tests[3]\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "# soft_env_10, soft_env_20, soft_env_50, soft_env_100 = soft_envs[0], soft_envs[1], soft_envs[2], soft_envs[3]\n",
    "\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168527d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=334, train/reward=-19.0, train/loss=-6.29, val/reward=-17.8]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s, v_num=334, train/reward=-19.0, train/loss=-6.29, val/reward=-17.8]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP3 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP3.fit(soft_models[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76561b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=100, S=12, EV=12 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 83 | Mean Trained Test Cost (Constrained): 5.607179\n",
      "Scale: 20 | FeasibleCounts: 26 | Mean Trained Test Cost (Constrained): 7.925522\n",
      "Scale: 50 | FeasibleCounts: 46 | Mean Trained Test Cost (Constrained): 15.370482\n",
      "Scale: 100 | FeasibleCounts: 78 | Mean Trained Test Cost (Constrained): 29.496206\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c3 = soft_models[3].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c3, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=100, S=12, EV=12 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c66fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hard_envs, soft_envs, soft_models, soft_policies\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af225642",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "# hard_env_10, hard_env_20, hard_env_50, hard_env_100 = hard_envs[0], hard_envs[1], hard_envs[2], hard_envs[3]\n",
    "# td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST = td_tests[0], td_tests[1], td_tests[2], td_tests[3]\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "# soft_env_10, soft_env_20, soft_env_50, soft_env_100 = soft_envs[0], soft_envs[1], soft_envs[2], soft_envs[3]\n",
    "\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 512\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6c172e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "soft_policies = []\n",
    "for soft_env in soft_envs:\n",
    "    soft_policy = AttentionModelPolicy(env_name=soft_env.name,\n",
    "                              embed_dim=256,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,)\n",
    "    soft_policies.append(soft_policy)\n",
    "\n",
    "soft_models = []\n",
    "for soft_env, soft_policy in zip(soft_envs, soft_policies):\n",
    "    soft_model = POMO(soft_env,\n",
    "                soft_policy,\n",
    "                 # baseline=\"rollout\",\n",
    "                batch_size=BATCH_SIZE,\n",
    "                train_data_size=TRAIN_DATA_SIZE,\n",
    "                val_data_size=VAL_DATA_SIZE,\n",
    "                optimizer_kwargs={\"lr\": 1e-4, \n",
    "                                  \"weight_decay\": 1e-6})\n",
    "    soft_models.append(soft_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95a2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(rewards, infeasibility, soft=False):\n",
    "    valid_rewards = []\n",
    "    if soft:\n",
    "        for infeasible, reward in zip(infeasibility, rewards):\n",
    "            if -reward > 1000 or infeasible:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    else:\n",
    "        for reward in  rewards:\n",
    "            if -reward > 1000:\n",
    "                pass\n",
    "            else:\n",
    "                valid_rewards.append(reward)\n",
    "    return np.array(valid_rewards)\n",
    "\n",
    "\n",
    "def get_reward_and_check(policy, test_data, env_scale, soft=False):\n",
    "    rewards_trained = []\n",
    "    num_valids = []\n",
    "    for td_i, env_i in zip(test_data, env_scale):\n",
    "        out = policy(td_i.clone(), \n",
    "                    env=env_i, \n",
    "                    phase=\"test\", \n",
    "                    feasibility_check=True, \n",
    "                    decode_type=\"greedy\", \n",
    "                    return_actions=True)\n",
    "        valid_out = validity_check(out['reward'].cpu().numpy(), out[\"infeasibility\"], soft=soft)\n",
    "        rewards_trained.append(valid_out) \n",
    "        if soft:\n",
    "            num_feasible = td_i.batch_size - sum(out[\"infeasibility\"]).cpu().numpy()\n",
    "            num_valids.append(len(valid_out)+num_feasible)\n",
    "        else:\n",
    "            num_valids.append(len(valid_out))       \n",
    "    return rewards_trained, num_valids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476b2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:18<00:00, 10.98it/s, v_num=335, train/reward=-3.27, train/loss=-0.0774, val/reward=-3.27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:18<00:00, 10.90it/s, v_num=335, train/reward=-3.27, train/loss=-0.0774, val/reward=-3.27]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP0 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP0.fit(soft_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d0420c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=10, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 82 | Mean Trained Test Cost (Constrained): 5.027235\n",
      "Scale: 20 | FeasibleCounts: 29 | Mean Trained Test Cost (Constrained): 7.132036\n",
      "Scale: 50 | FeasibleCounts: 16 | Mean Trained Test Cost (Constrained): 14.244226\n",
      "Scale: 100 | FeasibleCounts: 45 | Mean Trained Test Cost (Constrained): 27.166672\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c0 = soft_models[0].to(device)\n",
    "# Validity check is done with hard envs\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c0, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=10, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2db144ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ae2b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:35<00:00,  5.70it/s, v_num=336, train/reward=-4.39, train/loss=-0.169, val/reward=-4.38]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [00:35<00:00,  5.68it/s, v_num=336, train/reward=-4.39, train/loss=-0.169, val/reward=-4.38]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP1 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP1.fit(soft_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32b94626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=20, S=3, EV=3 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 59 | Mean Trained Test Cost (Constrained): 6.807777\n",
      "Scale: 20 | FeasibleCounts: 2 | Mean Trained Test Cost (Constrained): 9.660480\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost (Constrained): nan\n",
      "Scale: 100 | FeasibleCounts: 1 | Mean Trained Test Cost (Constrained): 31.319660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_27864\\1160707197.py:7: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c1 = soft_models[1].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c1, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=20, S=3, EV=3 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d95f68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c2f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:56<00:00,  1.71it/s, v_num=337, train/reward=-7.30, train/loss=-1.48, val/reward=-6.89] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [01:56<00:00,  1.71it/s, v_num=337, train/reward=-7.30, train/loss=-1.48, val/reward=-6.89]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP2 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP2.fit(soft_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "774f1127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=50, S=6, EV=6 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 61 | Mean Trained Test Cost (Constrained): 6.242512\n",
      "Scale: 20 | FeasibleCounts: 5 | Mean Trained Test Cost (Constrained): 8.292636\n",
      "Scale: 50 | FeasibleCounts: 1 | Mean Trained Test Cost (Constrained): 15.748408\n",
      "Scale: 100 | FeasibleCounts: 13 | Mean Trained Test Cost (Constrained): 32.167564\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c2 = soft_models[2].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c2, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=50, S=6, EV=6 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1074158",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rewards_c_trained, num_c_valid \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea057d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "def enforce_reproducibility(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [num_loc, num_station, num_ev]\n",
    "settings =[[10, 3, 3], [20, 3, 3], [50, 6, 6], [100, 12,12]]\n",
    "hard_envs = []\n",
    "td_tests = []   # Hard env setting for test (cf. get_action_mask() is different)\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    hard_envs.append(env)\n",
    "    td_init = env.reset(batch_size=[100]).to(device)\n",
    "    td_tests.append(td_init)\n",
    "# hard_env_10, hard_env_20, hard_env_50, hard_env_100 = hard_envs[0], hard_envs[1], hard_envs[2], hard_envs[3]\n",
    "# td_10_TEST, td_20_TEST, td_50_TEST, td_100_TEST = td_tests[0], td_tests[1], td_tests[2], td_tests[3]\n",
    "\n",
    "soft_envs = []\n",
    "for num_loc, num_station, num_ev in settings:\n",
    "    enforce_reproducibility(0)\n",
    "    env = EVRPTWEnv(generator_params={'num_loc': num_loc, \n",
    "                                        'num_station': num_station,\n",
    "                                        'vehicle_limit': num_ev,\n",
    "                                        'vehicle_speed': 5,\n",
    "                                        'vehicle_capacity': 1.5,\n",
    "                                        'max_time': 1,\n",
    "                                        'horizon': 1,\n",
    "                                        'fuel_consumption_rate': 0.25,\n",
    "                                        'inverse_recharge_rate': 0.25})\n",
    "    env.soft = True ## Soft setting\n",
    "    soft_envs.append(env)\n",
    "# soft_env_10, soft_env_20, soft_env_50, soft_env_100 = soft_envs[0], soft_envs[1], soft_envs[2], soft_envs[3]\n",
    "\n",
    "\n",
    "# MAX_EPOCH = 50\n",
    "# BATCH_SIZE = 512\n",
    "# TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "# VAL_DATA_SIZE = BATCH_SIZE * 50\n",
    "MAX_EPOCH = 10\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_DATA_SIZE = BATCH_SIZE * 200\n",
    "VAL_DATA_SIZE = BATCH_SIZE * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b817d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | env      | EVRPTWEnv            | 0      | train\n",
      "1 | policy   | AttentionModelPolicy | 3.6 M  | train\n",
      "2 | baseline | SharedBaseline       | 0      | train\n",
      "----------------------------------------------------------\n",
      "3.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 M     Total params\n",
      "14.241    Total estimated model params size (MB)\n",
      "126       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [02:54<00:00,  1.15it/s, v_num=339, train/reward=-10.2, train/loss=-0.869, val/reward=-10.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 200/200 [02:54<00:00,  1.14it/s, v_num=339, train/reward=-10.2, train/loss=-0.869, val/reward=-10.3]\n"
     ]
    }
   ],
   "source": [
    "trainer_C_STEP3 = RL4COTrainer(\n",
    "    max_epochs=MAX_EPOCH,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "trainer_C_STEP3.fit(soft_models[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9929d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained with Environment of C=100, S=12, EV=12 (Constrained)\n",
      "Scale: 10 | FeasibleCounts: 42 | Mean Trained Test Cost (Constrained): 6.956683\n",
      "Scale: 20 | FeasibleCounts: 1 | Mean Trained Test Cost (Constrained): 9.733961\n",
      "Scale: 50 | FeasibleCounts: 0 | Mean Trained Test Cost (Constrained): nan\n",
      "Scale: 100 | FeasibleCounts: 0 | Mean Trained Test Cost (Constrained): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyosi\\AppData\\Local\\Temp\\ipykernel_30300\\177768409.py:7: RuntimeWarning: Mean of empty slice.\n",
      "  print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")\n",
      "c:\\Users\\hyosi\\anaconda3\\envs\\rl4co\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "scale = [10, 20, 50, 100]\n",
    "policy_c3 = soft_models[3].to(device)\n",
    "rewards_c_trained, num_c_valid = get_reward_and_check(policy_c3, td_tests, hard_envs, soft=False)\n",
    "\n",
    "print(\"\\nTrained with Environment of C=100, S=12, EV=12 (Constrained)\")\n",
    "for i, s in enumerate(scale):\n",
    "    print(f\"Scale: {s} | FeasibleCounts: {num_c_valid[i]} | Mean Trained Test Cost (Constrained): {-rewards_c_trained[i].mean():3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d67eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581b2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
